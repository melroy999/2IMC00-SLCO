#include <stdbool.h>
#include <cooperative_groups.h>
using namespace cooperative_groups;

// type of vectortree nodes used.
{% if vectorsize < 32 %}
#define nodetype uint32_t
#define compressed_nodetype uint32_t
{% else %}
#define nodetype uint64_t
{% if not compact_hash_table %}
#define compressed_nodetype uint64_t
{% else %}
#define compressed_nodetype uint32_t
{% endif %}
{% endif %}
// type of global memory indices used.
{% if vectorsize < 63 %}
{% if nr_bits_address_root > 32 %}
#define indextype uint64_t
{% else %}
#define indextype uint32_t
{% endif %}
{% else %}
#define indextype uint32_t
{% endif %}
// type of shared memory elements used.
{% if vectorsize > 30 and vectorsize <= 62 %}
#define shared_inttype uint64_t
{% else %}
#define shared_inttype uint32_t
{% endif %}
// type for shared memory cache indices.
#define shared_indextype uint16_t
// type of state machine state.
{% if max_statesize <= 8 %}
#define statetype uint8_t
{% elif max_statesize <= 16 %}
#define statetype uint16_t
{% elif max_statesize <= 32 %}
#define statetype uint32_t
{% else %}
#define statetype uint64_t
{% endif %}
// types of data elements.
#define elem_inttype int32_t
#define elem_chartype int8_t
#define elem_booltype bool
// type for array and channel buffer indexing.
{% if max_arrayindexsize <= 8 %}
#define array_indextype int8_t
{% elif max_arrayindexsize <= 16 %}
#define array_indextype int16_t
{% else %}
#define array_indextype int32_t
{% endif %}
// type for indexing in variable buffers.
{% if max_buffer_allocs <= 8 %}
#define buffer_indextype int8_t
{% elif max_buffer_allocs <= 16 %}
#define buffer_indextype int16_t
{% else %}
#define buffer_indextype int32_t
{% endif %}
// type for vector node IDs.
{% if vectortree|length < 2**8 %}
#define vectornode_indextype uint8_t
{% elif vectortree|length < 2**16 %}
#define vectornode_indextype uint16_t
{% elif vectortree|length < 2**32 %}
#define vectornode_indextype uint32_t
{% elif vectortree|length < 2**64 %}
#define vectornode_indextype uint32_t
{% endif %}

// GPU constants.
static const int WARP_SIZE = 32;
__constant__ shared_inttype d_shared_cache_size;
{% if not compact_hash_table %}
__constant__ indextype d_hash_table_size;
{% else %}
__constant__ uint64_t d_non_root_offset;
{% endif %}

// GPU configuraton.
static const int KERNEL_ITERS = 1;
static const int NR_BLOCKS = {{nrblocks}};

// Thread ids and dimensions.
#define GRID_SIZE 				gridDim.x
#define BLOCK_SIZE				blockDim.x
#define NR_THREADS				(GRID_SIZE * BLOCK_SIZE)

#define BLOCK_ID				blockIdx.x
#define THREAD_ID 				threadIdx.x
#define GLOBAL_THREAD_ID		((BLOCK_ID * BLOCK_SIZE) + THREAD_ID)
#define WARP_ID					(THREAD_ID / WARP_SIZE)
#define GLOBAL_WARP_ID			(((BLOCK_SIZE / WARP_SIZE) * BLOCK_ID) + WARP_ID)
#define NR_WARPS_PER_BLOCK		(BLOCK_SIZE / WARP_SIZE)
#define NR_WARPS				(NR_WARPS_PER_BLOCK * GRID_SIZE)
#define LANE					(THREAD_ID & 0x0000001F)

// Constant representing empty array index entry.
#define EMPTY_INDEX -1
// Constant used to initialise state variables.
#define NO_STATE {{no_state_constant}}
// Empty local cache element (exploits that a vectornode cannot be marked 'new' without being marked 'root')
#define EMPTYVECT32 			0xBFFFFFFF
#define EMPTYVECT16				0xFFFF
{% if vectorsize > 62 %}
#define CACHE_POINTERS_NEW_LEAF	0x40000000
{% endif %}

// Retry constant to determine number of retries for element insertion.
#define RETRYFREQ 7
#define NR_HASH_FUNCTIONS 32
// Number of retries in local cache.
#define CACHERETRYFREQ 20

const size_t Mb = 1<<20;

// CONSTANTS FOR SHARED MEMORY CACHES
// Offsets calculations for shared memory arrays
#define OPENTILELEN				{{tilesize}}
#define LASTSEARCHLEN			({{nrthreadsperblock}}/WARP_SIZE)

// Offsets in shared memory from which loaded data can be read.
#define SH_OFFSET 5
#define OPENTILEOFFSET 			(SH_OFFSET)
#define LASTSEARCHOFFSET		(OPENTILEOFFSET+OPENTILELEN)
#define CACHEOFFSET 			(LASTSEARCHOFFSET+LASTSEARCHLEN)

// Shared memory work tile size in nr. of warps
#define OPENTILE_WARP_WIDTH		{{nr_warps_per_tile}}

// Error value to indicate a full global hash table.
{% if nr_bits_address_root < 32 %}
#define HASHTABLE_FULL 0xFFFFFFFF
{% else %}
#define HASHTABLE_FULL 0xFFFFFFFFFFFFFFFF
{% endif %}
// Error value to indicate that a shared memory cache is full.
// Assumption: the cache cannot store 2^16 or more elements.
#define CACHE_FULL 0xFFFF

// Shared memory local progress flags
#define ITERATIONS				(shared[0])
#define CONTINUE				(shared[1])
#define OPENTILECOUNT			(shared[2])
#define WORKSCANRESULT			(shared[3])
#define SCAN					(shared[4])

// The number of state machines in the model.
#define NR_SMS					{{smnames|length}}

// CONSTANTS FOR GLOBAL MEMORY HASH TABLE
{% if not compact_hash_table %}
// Empty hash table element (exploits that a vectornode cannot be marked 'new' without being marked 'root')
{% if vectorsize <= 30 %}
#define EMPTY_NODE 	0xBFFFFFFF
{% else %}
#define EMPTY_NODE 	0xBFFFFFFFFFFFFFFF
{% endif %}
{% else %}
// Empty root hash table element
#define EMPTY_COMPRESSED_NODE	0xFFFFFFFF
// Empty internal hash table element (exploits that an uncompressed internal vectornode always has its highest bit set to 0)
#define EMPTY_NODE				0xFFFFFFFFFFFFFFFF
{% endif %}

// GPU shared memory array.
extern __shared__ volatile shared_inttype shared[];

// Structure of the state vector:
// {{vectorstructure_string}}
{% if vectorsize > 62 and not no_smart_fetching %}

// Bitmask to identify parts of the state vector that contain state machine states.
#define VECTOR_SMPARTS			{{smart_vectortree_fetching_bitmask["smstates"]}}
{% endif %}

// *** START BIT OPERATIONS ***

{% if compact_hash_table %}
// Bit left rotation function for {{nr_bits_address_internal*2}} bits.
inline __device__ nodetype rot_{{nr_bits_address_internal*2}}(const nodetype x, uint8_t i) {
	return (x << i) | (x >> ({{nr_bits_address_internal*2}}-i));
}

// XOR two times bit left rotation function for {{nr_bits_address_internal*2}} bits.
inline __device__ nodetype xor_rot2_{{nr_bits_address_internal*2}}(nodetype x, uint8_t a, uint8_t b) {
	nodetype y = x ^ rot_{{nr_bits_address_internal*2}}(x,a);
	y = y ^ rot_{{nr_bits_address_internal*2}}(y,b);
	return y &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
}

// Inverse function for XOR two times bit left rotation, mod {{nr_bits_address_internal*2}}.
inline __device__ nodetype xor_rot2_inv_{{nr_bits_address_internal*2}}(nodetype x, uint8_t a, uint8_t b) {
	nodetype y = xor_rot2_{{nr_bits_address_internal*2}}(x, a, b);
	uint8_t a1 = (8*a) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	uint8_t b1 = (8*b) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	y = xor_rot2_{{nr_bits_address_internal*2}}(y, a1, b1);
	a1 = (a1+a1) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	b1 = (b1+b1) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	y = xor_rot2_{{nr_bits_address_internal*2}}(y, a1, b1);
	a1 = (a1+a1) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	b1 = (b1+b1) & {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
	y = xor_rot2_{{nr_bits_address_internal*2}}(y, a1, b1);
	return y;
}

{% endif %}
// Bit left rotation function for 64 bits.
inline __device__ uint64_t rot_64(const uint64_t x, uint8_t i) {
	return (x << i) | (x >> 64-i);
}

// XOR two times bit left rotation function for 64 bits.
inline __device__ uint64_t xor_rot2_64(uint64_t x, uint8_t a, uint8_t b) {
	nodetype y = x ^ rot_64(x,a);
	return y ^ rot_64(y,b);
}

// *** END BIT OPERATIONS ***

// *** START FUNCTIONS FOR {% if vectorsize > 62 %}VECTOR TREE {% endif %}NODE MANIPULATION AND STORAGE TO THE SHARED MEMORY CACHE ***

// Mark state as new or old.
inline __device__ compressed_nodetype mark_new(compressed_nodetype node) {
{% if vectorsize <= 30 or compact_hash_table %}
	return node | 0x80000000;
{% else %}
	return node | 0x8000000000000000;
{% endif %}
}

inline __device__ compressed_nodetype mark_old(compressed_nodetype node) {
{% if vectorsize <= 30 or compact_hash_table %}
	return node & 0x7FFFFFFF;
{% else %}
	return node & 0x7FFFFFFFFFFFFFFF;
{% endif %}
}

{% if vectorsize > 62 %}
inline __device__ nodetype mark_non_root_old(nodetype node) {
	return node & 0x7FFFFFFFFFFFFFFF;
}
{% endif %}
// Check whether state is new.
{% if not compact_hash_table %}
// This is the case if the highest two bits are set
// (if only the highest bit is set, the node is actually empty).
{% else %}
// This is the case if the highest bit is set.
{% endif %}
inline __device__ bool is_new(compressed_nodetype node) {
{% if compact_hash_table %}
	return (node & 0x80000000) == 0x80000000;
{% elif vectorsize <= 30 %}
	return (node & 0xC0000000) == 0xC0000000;
{% else %}
	return (node & 0xC000000000000000) == 0x8000000000000000;
{% endif %}
}

// Check whether the highest 32-bits of a node in shared memory are set as new.
inline __device__ bool head_is_new(shared_inttype node) {
	return (node & 0x80000000) != 0;
}

{% if not compact_hash_table and vectorsize > 31 %}
// Mark a node as root.
inline __device__ inttype mark_root(compressed_nodetype node) {
	return node | 0x4000000000000000;
}

// Check whether node is root.
inline __device__ bool is_root(compressed_nodetype node) {
	return (node & 0x4000000000000000) != 0;
}

{% endif %}
// Check whether the highest 32-bits of a node in shared memory are set as root.
inline __device__ bool head_is_root(shared_inttype node) {
	return (node & 0x40000000) != 0;
}

{% if vectorsize > 62 %}
// Function to traverse one step in state vector tree (stored in shared memory).
inline __device__ shared_indextype sv_step(shared_indextype node_index, bool goright) {
	shared_indextype index = 0;
	shared_inttype tmp = shared[CACHEOFFSET+node_index+2];
	if (!goright) {
		asm("{\n\t"
			" .reg .u32 t1;\n\t"
			" bfe.u32 t1, %1, 15, 15;\n\t"
			" cvt.u16.u32 %0, t1;\n\t"
			"}" : "=h"(index) : "r"(tmp));
	}
	else {
		asm("{\n\t"
			" .reg .u32 t1;\n\t"
			" bfe.u32 t1, %1, 0, 15;\n\t"
			" cvt.u16.u32 %0, t1;\n\t"
			"}" : "=h"(index) : "r"(tmp));
	}
	return index;
}

{% endif %}
// Get left or right half of a 64-bit integer
inline __device__ uint32_t get_left(uint64_t node) {
	uint32_t result;
	asm("{\n\t"
		" .reg .u64 t1;\n\t"
		" bfe.u64 t1, %1, 32, 32;\n\t"
		" cvt.u32.u64 %0, t1;\n\t"
		"}" : "=r"(result) : "l"(node));
	return result;
}

inline __device__ uint32_t get_right(uint64_t node) {
	uint32_t result;
	asm("{\n\t"
		" cvt.u32.u64 %0, %1;\n\t"
		"}" : "=r"(result) : "l"(node));
	return result;
}

// Combine two halfs of a 64-bit integer
inline __device__ uint64_t combine_halfs(uint32_t n1, uint32_t n2) {
	uint64_t node = (uint64_t) n2;
	uint64_t node2 = (uint64_t) n1;
	asm("{\n\t"
		" bfi.u64 %0, %1, %0, 32, 32;\n\t"
		"}" : "+l"(node) : "l"(node2));
	return node;
}

{% for i in range(0,vectorstructure|length) %}
inline __device__ nodetype get_vectorpart_{{i}}(shared_indextype node_index) {
	{% if vectorsize <= 30 %}
	// The node is directly stored in the work tile.
	return shared[OPENTILEOFFSET+node_index];
	{% else %}
	{% if i|get_vector_tree_to_part_navigation|length > 0 %}
	shared_indextype index = node_index;
	{% endif %}
	{% for b in i|get_vector_tree_to_part_navigation %}
	index = sv_step(index, {% if b %}true{% else %}false{% endif %});
	{% endfor %}
	nodetype part;
	asm("{\n\t"
		" mov.b64 %0,{ %1, %2 };\n\t"
		"}" : "=l"(part) : "r"(shared[CACHEOFFSET+{% if i|get_vector_tree_to_part_navigation|length > 0 %}index{% else %}node_index{% endif %}]), "r"(shared[CACHEOFFSET+{% if i|get_vector_tree_to_part_navigation|length > 0 %}index{% else %}node_index{% endif %}+1]));
	return part;
	{% endif %}
}

{% endfor %}
// Retrieval functions for vector parts from shared memory.
{% if vectorsize > 62 %}
We ignore shared memory node pointers (cache pointers).
{% endif %}
inline __device__ nodetype get_vectorpart(shared_indextype node_index, vectornode_indextype part_id) {
	switch (part_id) {
	  {% for i in range(0,vectorstructure|length) %}
	  case {{i}}:
	  	return get_vectorpart_{{i}}(node_index);
	  {% endfor %}
	  default:
	  	return 0;
	}
}

{% if vectorsize > 62 %}
// Retrieval functions for vector tree nodes from shared memory, including shared memory node pointers (cache pointers).
inline __device__ void get_vectortree_node(nodetype *node, shared_inttype *d_cachepointers, shared_indextype node_index, vectornode_indextype i) {
	switch (i) {
	  {% for i in range(0,vectortree|length) %}
	  case {{i}}:
	  	get_vectortree_node_{{i}}(node, d_cachepointers, node_index);
	  {% endfor %}
	  default:
	  	return;
	}
}
{% for i in range(0,vectortree|length) %}

inline __device__ void get_vectortree_node_{{i}}(nodetype *node, shared_inttype *d_cachepointers, shared_indextype node_index) {
	{% if i|get_vector_tree_to_node_navigation|length > 0 %}
	shared_indextype index = node_index;
	{% endif %}
	{% for b in i|get_vector_tree_to_node_navigation %}
	index = sv_step(index, {% if b %}true{% else %}false{% endif %});
	{% endfor %}
	asm("{\n\t"
		" mov.b64 %0,{ %1, %2 };\n\t"
		"}" : "=l"(*node) : "r"(shared[CACHEOFFSET+{% if i|get_vector_tree_to_node_navigation|length > 0 %}index{% else %}node_index{% endif %}]), "r"(shared[CACHEOFFSET+{% if i|get_vector_tree_to_node_navigation|length > 0 %}index{% else %}node_index{% endif %}+1]));
	*d_cachepointers = shared[CACHEOFFSET+{% if i|get_vector_tree_to_node_navigation|length > 0 %}index{% else %}node_index{% endif %}+2];
}
{% endfor %}

// Function to traverse one step in state vector tree (stored in global or host memory).
inline __host__ __device__ nodetype direct_sv_step(compressed_nodetype *q, nodetype node, bool goright) {
	indextype index = get_pointer_from_vectortree_node(node, goright);
	{% if not compact_hash_table %}
	return q[index];
	{% else %}
	compressed_nodetype p1, p2;
	p1 = q[d_non_root_offset+(index*2)];
	p2 = q[d_non_root_offset+(index*2)+1];
	return combine_halfs((shared_inttype) p1, (shared_inttype) p2);
	{% endif %}
}

// Functions to retrieve vector parts from global or host memory.
{% for i in range(0,vectorstructure|length) %}

inline __host__ __device__ nodetype direct_get_vectorpart_{{i}}(compressed_nodetype *q, nodetype node) {
	{% if vectorsize <= 30 %}
	return node;
	{% else %}
	{% if i|get_vector_tree_to_part_navigation|length > 0 %}
	nodetype tmp = node;
	{% endif %}
	{% for b in i|get_vector_tree_to_part_navigation %}
	tmp = sv_step(q, tmp, {% if b %}true{% else %}false{% endif %});
	{% endfor %}
	return tmp;
	{% endif %}
}
{% endfor %}

// Cache pointers set functions.
inline __device__ void set_left_cache_pointer(shared_inttype *pointers, shared_indextype new_pointer) {
	asm("{\n\t"
		" bfi.u32 %0, %1, %0, 15, 15;\n\t"
		"}" : "+r"(*pointers) : "h"(new_pointer));
}

inline __device__ void set_right_cache_pointer(shared_inttype *pointers, shared_indextype new_pointer) {
	asm("{\n\t"
		" bfi.u32 %0, %1, %0, 0, 15;\n\t"
		"}" : "+r"(*pointers) : "h"(new_pointer));
}

inline __device__ bool cache_pointers_are_marked_new_leaf(shared_inttype pointers) {
	return pointers == CACHE_POINTERS_NEW_LEAF;
}

inline __device__ void set_cache_pointers_to_global_address(shared_inttype *pointers, indextype address) {
	// The highest bit in pointers is set to indicate that it now stores a global memory address.
	*pointers = address | 0x80000000;
}

inline __device__ bool cache_pointers_contain_global_address(shared_inttype pointers) {
	return (pointers & 0x80000000) != 0;
}

// Vectornode reset functions.
inline __device__ void reset_left_in_vectortree_node(nodetype *node) {
{% if not compact_hash_table %}
	asm("{\n\t"
		" bfi.u64 %0, {{((nr_bits_address_root|pow2)-1)|bitshift_left(64-2-nr_bits_address_root)|hexa}}, %0, {{64-2-nr_bits_address_root}}, {{nr_bits_address_root}};\n\t"
		"}" : "+l"(*node));
{% else %}
	asm("{\n\t"
		" bfi.u64 %0, {{((nr_bits_address_internal|pow2)-1)|bitshift_left(64-1-nr_bits_address_internal)|hexa}}, %0, {{64-1-nr_bits_address_internal}}, {{nr_bits_address_internal}};\n\t"
		"}" : "+l"(*node));
{% endif %}
}

inline __device__ void reset_right_in_vectortree_node(nodetype *node) {
{% if not compact_hash_table %}
	asm("{\n\t"
		" bfi.u64 %0, {{((nr_bits_address_root|pow2)-1)|hexa}}, %0, 0, {{nr_bits_address_root}};\n\t"
		"}" : "+l"(*node));
{% else %}
	asm("{\n\t"
		" bfi.u64 %0, {{((nr_bits_address_internal|pow2)-1)|hexa}}, %0, 0, {{nr_bits_address_internal}};\n\t"
		"}" : "+l"(*node));
{% endif %}
}

// Vectornode set functions.
inline __device__ void set_left_in_vectortree_node(nodetype *node, indextype address) {
{% if not compact_hash_table %}
	asm("{\n\t"
		" bfi.u64 %0, %1, %0, {{nr_bits_address_internal}}, {{nr_bits_address_internal}};\n\t"
		"}" : "+l"(*node) : "r"(address));
{% else %}
	asm("{\n\t"
		" bfi.u64 %0, %1, %0, {{64-1-nr_bits_address_internal}}, {{nr_bits_address_internal}};\n\t"
		"}" : "+l"(*node) : "r"(address));
{% endif %}
}

inline __device__ void set_right_in_vectortree_node(nodetype *node, indextype address) {
	asm("{\n\t"
		" bfi.u64 %0, %1, %0, 0, {{nr_bits_address_internal}};\n\t"
		"}" : "+l"(*node) : "r"(address));
}

// Vectornode get functions.
inline __host__ __device__ indextype get_pointer_from_vectortree_node(nodetype node, bool choice) {
	indextype result;
{% if not compact_hash_table %}
	asm("{\n\t"
		" .reg .u64 t1;\n\t"
		" bfe.u64 t1, %1, %2, {{nr_bits_address_root}};\n\t"
		" cvt.u32.u64 %0, t1;\n\t"
		"}" : "+r"(result) : "l"(node), "r"((1-(choice ? 1 : 0))*{{64-2-nr_bits_address_root}}));
{% else %}
	asm("{\n\t"
		" .reg .u64 t1;\n\t"
		" bfe.u64 t1, %1, %2, {{nr_bits_address_internal}};\n\t"
		" cvt.u32.u64 %0, t1;\n\t"
		"}" : "+r"(result) : "l"(node), "r"((1-(choice ? 1 : 0))*{{64-1-nr_bits_address_internal}}));
{% endif %}
	return result;
}

// Vectornode check for a left or right pointer gap.
inline __device__ bool vectortree_node_contains_left_gap(nodetype node) {
{% if not compact_hash_table %}
	return (node & {{((nr_bits_address_root|pow2)-1)|bitshift_left(64-2-nr_bits_address_root)|hexa}}) == {{((nr_bits_address_root|pow2)-1)|bitshift_left(64-2-nr_bits_address_root)|hexa}};
{% else %}
	return (node & {{((nr_bits_address_internal|pow2)-1)|bitshift_left(64-1-nr_bits_address_internal)|hexa}}) == {{((nr_bits_address_internal|pow2)-1)|bitshift_left(64-1-nr_bits_address_internal)|hexa}};
{% endif %}
}

inline __device__ bool vectortree_node_contains_right_gap(nodetype node) {
{% if not compact_hash_table %}
	return (node & {{((nr_bits_address_root|pow2)-1)|hexa}}) == {{((nr_bits_address_root|pow2)-1)|hexa}};
{% else %}
	return (node & {{((nr_bits_address_internal|pow2)-1)|hexa}}) == {{((nr_bits_address_internal|pow2)-1)|hexa}};
{% endif %}
}

{% endif %}
// Cache hash function.
inline __device__ shared_indextype CACHE_HASH(nodetype node) {
	uint64_t node1 = xor_rot2_64((uint64_t) node, 38, 14);
	node1 ^= 0xD1B54A32D192ED03L;
	node1 *= 0xAEF17502108EF2D9L;
	{{12|cuda_xor_lr(64, 1)}}
	{{37|cuda_xor_lr(64, 1)}}
	node1 *= 0xd1b549a75a913001L;
	{{43|cuda_xor_r3(31, 23, 1)}}
	node1 *= 0xdb4f0ad2012a3801L;
	{{28|cuda_xor_r(1)}}
	return (shared_indextype) {% if vectorsize > 62 %}3*{% elif vectorsize > 30 %}2*{% endif %}((node1 & 0x000000000000FFFF) * (d_shared_cache_size-CACHEOFFSET{% if vectorsize > 62 %}/3{% elif vectorsize > 30 %}/2{% endif %})) >> 16;
}

// Store a vectortree node in the cache.
// Return address if successful, HASHTABLE_FULL if cache is full.
{% if vectorsize <= 62 %}
inline __device__ shared_inttype STOREINCACHE(nodetype node) {
{% else %}
inline __device__ shared_inttype STOREINCACHE(nodetype node, shared_inttype cache_pointers) {
{% endif %}
	uint8_t i = 0;
	shared_indextype addr;
	shared_inttype element;
	{% if vectorsize > 62 %}
	shared_inttype part1, part2;

	// Split the node in two.
	part1 = get_left(node);
	part2 = get_right(node);
	{% endif %}
	addr = CACHE_HASH(node);
	while (i < CACHERETRYFREQ) {
		element = atomicCAS((shared_inttype *) &(shared[CACHEOFFSET+addr]), EMPTYVECT32, {% if vectorsize < 64%}node{% else %}part1{% endif %});
		if (element == EMPTYVECT32 || element == {% if vectorsize < 64%}node{% else %}part1{% endif %}) {
			// Successful storage.
			{% if vectorsize > 62 %}
			element = atomicCAS((shared_inttype *) &(shared[CACHEOFFSET+addr+1]), EMPTYVECT32, part2);
			if (element == EMPTYVECT32 || element == part2) {
				// Successful storage.
				element = atomicCAS((shared_inttype *) &(shared[CACHEOFFSET+addr+2], EMPTYVECT32, cache_pointers);
				if (element == EMPTYVECT32 || element == cache_pointers) {
					// Storage of node successful.
					return (shared_inttype) addr;
				}
				else {
					// Storage of node after all not successful. Try another address.
					{% if vectorsize < 31 %}
					addr++;
					if (addr >= d_shared_cache_size) {
						addr = 0;
					}
					{% elif vectorsize < 63 %}
					addr += 2;
					if (addr+1 >= d_shared_cache_size) {
						addr = 0;
					}
					{% else %}
					addr += 3;
					if (addr+2 >= d_shared_cache_size) {
						addr = 0;
					}
					{% endif %}
					i++;
					continue;
				}
			}
			else {
				// Storage of node after all not successful. Try another address.
				{% if vectorsize < 31 %}
				addr++;
				if (addr >= d_shared_cache_size) {
					addr = 0;
				}
				{% elif vectorsize < 63 %}
				addr += 2;
				if (addr+1 >= d_shared_cache_size) {
					addr = 0;
				}
				{% else %}
				addr += 3;
				if (addr+2 >= d_shared_cache_size) {
					addr = 0;
				}
				{% endif %}
				i++;
				continue;
			}
			{% else %}
			return (shared_inttype) addr;
			{% endif %}
		}
		else {
			// Storage of node after all not successful. Try another address.
			{% if vectorsize < 31 %}
			addr++;
			if (addr >= d_shared_cache_size) {
				addr = 0;
			}
			{% elif vectorsize < 63 %}
			addr += 2;
			if (addr+1 >= d_shared_cache_size) {
				addr = 0;
			}
			{% else %}
			addr += 3;
			if (addr+2 >= d_shared_cache_size) {
				addr = 0;
			}
			{% endif %}
			i++;		
		}
	}
	// Storage of node not successful. We conclude that the cache is full.
	return CACHE_FULL;
}

// *** END FUNCTIONS FOR {% if vectorsize > 62 %}VECTOR TREE {% endif %}NODE MANIPULATION AND STORAGE TO THE SHARED MEMORY CACHE ***

// *** START KERNELS AND FUNCTIONS FOR {% if vectorsize > 62 %}VECTOR TREE {% endif %}NODE STORAGE AND RETRIEVAL TO/FROM THE GLOBAL MEMORY HASH TABLE ***

{% if compact_hash_table %}
// Initial bitmixer functions.
inline __device__ nodetype HASH_INIT(nodetype node, indextype offset) {
	if (offset != 0) {
		return RHASH_INIT(id, node);
	}
	else {
		return UHASH_INIT(id, node);
	}
}

inline __device__ nodetype RHASH_INIT(nodetype node) {
	nodetype node1 = xor_rot2_{{nr_bits_address_internal*2}}(node, 38, 14);
	node1 ^= 0x01b54a32d192ed03L;
	node1 *= 0x02f17502108ef2d9L;
	return node1;
}

inline __device__ nodetype RHASH_INIT_INVERSE(nodetype node) {
	node1 = node;
	node1 *= 0x4ca582acb86d69L;
	node1 ^= 0x2106ccfa448e5abL;
	node1 = xor_rot2_inv_{{nr_bits_address_internal*2}}(node, 38, 14);
	return node1;
}

// Hash functions.
inline __device__ nodetype HASH(uint8_t id, nodetype node, indextype offset) {
	if (offset != 0) {
		return (nodetype) UHASH(id, node);
	}
	else {
		return RHASH(id, node);
	}
}

inline __device__ nodetype RHASH(uint8_t id, nodetype node) {
	nodetype node1 = node;
	switch (id) {
		case 0:
			{{12|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{37|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x346d5269d6a44c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3(31, 23, 3)}}
			node1 *= 0x36d3c2b4804a8e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r(3)}}
			break;
		case 1:
			{{10|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3866c0692e5e421L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{40|cuda_xor_r3(34, 19, 3)}}
			node1 *= 0x39838add4d38e61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r(3)}}
			break;
		case 2:
			{{14|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{39|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3a5787914312801L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{44|cuda_xor_r3(30, 15, 3)}}
			node1 *= 0x3afb7bb024c4681L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{30|cuda_xor_r(3)}}
			break;
		case 3:
			{{13|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{34|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3b7e13a202e41c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{39|cuda_xor_r3(33, 25, 3)}}
			node1 *= 0x3be88e9173fb7c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r(3)}}
			break;
		case 4:
			{{11|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3c4109af0f01241L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{23|cuda_xor_r3(30, 26, 3)}}
			node1 *= 0x3c8bbb336719fc1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_r(3)}}
			break;
		case 5:
			{{15|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{33|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3ccba0994f7af81L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{41|cuda_xor_r3(36, 20, 3)}}
			node1 *= 0x3d02e8d5ad09d61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{23|cuda_xor_r(3)}}
			break;
		case 6:
			{{34|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{12|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3d3335b9a01aac1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{38|cuda_xor_r3(42, 24, 3)}}
			node1 *= 0x3d5dc5b2dd89301L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{29|cuda_xor_r(3)}}
			break;
		case 7:
			{{23|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3d839037059b321L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r3(46, 23, 3)}}
			node1 *= 0x3da557a7a356621L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r(3)}}
			break;
		case 8:
			{{31|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{34|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3dc3b70f5d13b41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{29|cuda_xor_r3(40, 20, 3)}}
			node1 *= 0x3ddf2c9626244a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{27|cuda_xor_r(3)}}
			break;
		case 9:
			{{24|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{20|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3df81dfdd3d5e01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{40|cuda_xor_r3(33, 25, 3)}}
			node1 *= 0x3e0ee0bdbcd6ea1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{30|cuda_xor_r(3)}}
			break;
		case 10:
			{{10|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{19|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e23ba68e0e7381L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r3(46, 23, 3)}}
			node1 *= 0x3e36e66407cf201L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r(3)}}
			break;
		case 11:
			{{14|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{30|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e48961660141a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3(12, 26, 3)}}
			node1 *= 0x3e58f4f3df8a861L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{31|cuda_xor_r(3)}}
			break;
		case 12:
			{{19|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{41|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e68266fecc08a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{24|cuda_xor_r3(39, 21, 3)}}
			node1 *= 0x3e764a9bd2ba4c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{25|cuda_xor_r(3)}}
			break;
		case 13:
			{{28|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{15|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e837baf5cdd9e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{32|cuda_xor_r3(40, 24, 3)}}
			node1 *= 0x3e8fd1c4d2d9d01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{27|cuda_xor_r(3)}}
			break;
		case 14:
			{{43|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{32|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e9b61d7f9527a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{31|cuda_xor_r3(46, 28, 3)}}
			node1 *= 0x3ea63db9f9aa901L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r(3)}}
			break;
		case 15:
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{42|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3eb074fc94e0161L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{25|cuda_xor_r3(44, 29, 3)}}
			node1 *= 0x3eba165b7e383e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r(3)}}
			break;
		case 16:
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{49|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3ec32dcb8264481L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_r3(29, 44, 3)}}
			node1 *= 0x3ecbc7575141a21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{35|cuda_xor_r(3)}}
			break;
		case 17:
			{{45|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{29|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3ed3ec3963f4841L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{15|cuda_xor_r3(44, 33, 3)}}
			node1 *= 0x3edba5bb75d7341L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{41|cuda_xor_r(3)}}
			break;
		case 18:
			{{20|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{36|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3ee2fc3e0dbac21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{21|cuda_xor_r3(41, 13, 3)}}
			node1 *= 0x3ee9f6ba8914441L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{34|cuda_xor_r(3)}}
			break;
		case 19:
			{{10|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{8|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3ef09bb82cdbe21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_r3(11, 34, 3)}}
			node1 *= 0x3ef6f14ae3b4501L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{15|cuda_xor_r(3)}}
			break;
		case 20:
			{{29|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{50|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3efcfd121b9a201L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3(39, 49, 3)}}
			node1 *= 0x3f02c33f9a541c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{24|cuda_xor_r(3)}}
			break;
		case 21:
			{{38|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{31|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f08497eaba1a01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{50|cuda_xor_r3(34, 48, 3)}}
			node1 *= 0x3f0d9313139b901L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{44|cuda_xor_r(3)}}
			break;
		case 22:
			{{14|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{49|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f12a43ce6c0301L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{11|cuda_xor_r3(23, 11, 3)}}
			node1 *= 0x3f178047799bae1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{8|cuda_xor_r(3)}}
			break;
		case 23:
			{{20|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{19|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f1c2a814d54a41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{50|cuda_xor_r3(29, 28, 3)}}
			node1 *= 0x3f20a5bf510f741L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r(3)}}
			break;
		case 24:
			{{31|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{18|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f24f45c5a49c41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{39|cuda_xor_r3(14, 32, 3)}}
			node1 *= 0x3f2919aea827c81L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_r(3)}}
			break;
		case 25:
			{{26|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f2d1798bf827a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{18|cuda_xor_r3(24, 50, 3)}}
			node1 *= 0x3f30effeb7d35a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{25|cuda_xor_r(3)}}
			break;
		case 26:
			{{48|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{49|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f34a542fbc9a21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r3(33, 41, 3)}}
			node1 *= 0x3f3838cfc8b3a01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{17|cuda_xor_r(3)}}
			break;
		case 27:
			{{26|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{20|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f3bad0a59f2881L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{46|cuda_xor_r3(43, 23, 3)}}
			node1 *= 0x3f3f02e25afd0c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{18|cuda_xor_r(3)}}
			break;
		case 28:
			{{32|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{12|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f423cbf612eea1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{10|cuda_xor_r3(15, 49, 3)}}
			node1 *= 0x3f455b15e806c41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{29|cuda_xor_r(3)}}
			break;
		case 29:
			{{30|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{49|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f485fd255036a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{27|cuda_xor_r3(45, 36, 3)}}
			node1 *= 0x3f4b4b6a79ccae1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_r(3)}}
			break;
		case 30:
			{{28|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{17|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f4e204983b0bc1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{12|cuda_xor_r3(39, 34, 3)}}
			node1 *= 0x3f50de694fe52a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r(3)}}
			break;
		case 31:
			{{47|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			{{10|cuda_xor_lr(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3f53873be153f21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r3(39, 50, 3)}}
			node1 *= 0x3f561bb689cd3e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{7|cuda_xor_r(3)}}
			break;
	}
	return node1;
}

// Inverse hash functions.
inline __device__ nodetype HASH_INVERSE(uint8_t id, nodetype node) {
	nodetype node1 = node;
	switch (id) {
		case 0:
			{{28|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e340cf8be69b21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3_inv(31, 23, nr_bits_address_internal*2, 3)}}
			node1 *= 0x16e2e65fde04b41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{37|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{12|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 1:
			{{26|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x27e8bdf6b3595a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{40|cuda_xor_r3_inv(34, 19, nr_bits_address_internal*2, 3)}}
			node1 *= 0x3234705f3029fe1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};			
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{10|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 2:
			{{30|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x38516503a7df981L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{44|cuda_xor_r3_inv(30, 15, nr_bits_address_internal*2, 3)}}
			node1 *= 0x3880f7d420ed801L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{39|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{14|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 3:
			{{28|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3a638f15ba85841L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{39|cuda_xor_r3_inv(33, 25, nr_bits_address_internal*2, 3)}}
			node1 *= 0x20fabc04158ce41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{34|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{13|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 4:
			{{20|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3592d3c27c27041L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{23|cuda_xor_r3_inv(30, 26, nr_bits_address_internal*2, 3)}}
			node1 *= 0x4f6952eaf8fdc1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{11|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 5:
			{{23|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x1a0c447ad94c6a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{41|cuda_xor_r3_inv(36, 20, nr_bits_address_internal*2, 3)}}
			node1 *= 0x2a87df258789081L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{33|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{15|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 6:
			{{29|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0xa6775beb906d01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{38|cuda_xor_r3_inv(42, 24, nr_bits_address_internal*2, 3)}}
			node1 *= 0x37e24eee615e541L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{12|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{34|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 7:
			{{26|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x33b48646b8f9de1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r3_inv(46, 23, nr_bits_address_internal*2, 3)}}
			node1 *= 0x14eaae5968790e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{23|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 8:
			{{27|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x1fdf88f19a49f61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{29|cuda_xor_r3_inv(40, 20, nr_bits_address_internal*2, 3)}}
			node1 *= 0xdbbcfbf69154c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{34|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{31|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 9:
			{{30|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x2565bb394a9f561L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{40|cuda_xor_r3_inv(33, 25, nr_bits_address_internal*2, 3)}}
			node1 *= 0x209a299946a201L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{24|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 10:
			{{28|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x2749093cc470e01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{26|cuda_xor_r3_inv(46, 23, nr_bits_address_internal*2, 3)}}
			node1 *= 0x397388d192dcc81L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{19|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{10|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 11:
			{{31|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x31b72238ae7fba1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3_inv(12, 26, nr_bits_address_internal*2, 3)}}
			node1 *= 0x17db804c1d6e261L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{30|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{14|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 12:
			{{25|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x17cd12a8d2eeb41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{24|cuda_xor_r3_inv(39, 21, nr_bits_address_internal*2, 3)}}
			node1 *= 0xdda8affbefdb61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{41|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{19|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 13:
			{{27|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x13d6fbb801b6301L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{32|cuda_xor_r3_inv(40, 24, nr_bits_address_internal*2, 3)}}
			node1 *= 0x34aade611b82a21L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{15|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{28|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 14:
			{{26|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x303124e6af65701L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{31|cuda_xor_r3_inv(46, 28, nr_bits_address_internal*2, 3)}}
			node1 *= 0x2b47151bd0a7c61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{32|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{43|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 15:
			{{28|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x1941bdcc12c0021L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{25|cuda_xor_r3_inv(44, 29, nr_bits_address_internal*2, 3)}}
			node1 *= 0x998456ffaa62a1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{42|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 16:
			{{35|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x2efb706fdede9e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_r3_inv(29, 44, nr_bits_address_internal*2, 3)}}
			node1 *= 0x3933d59b50dfb81L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 17:
			{{41|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x21a8aeb5ab11cc1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{15|cuda_xor_r3_inv(44, 33, nr_bits_address_internal*2, 3)}}
			node1 *= 0x26923bf4120c7c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{29|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{45|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 18:
			{{34|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x399c741b25ccbc1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{21|cuda_xor_r3_inv(41, 13, nr_bits_address_internal*2, 3)}}
			node1 *= 0x31b1f4e059ed7e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{36|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{20|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 19:
			{{15|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x1880d14f55dbb01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_r3_inv(11, 34, nr_bits_address_internal*2, 3)}}
			node1 *= 0x201dedfc54d45e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{8|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{10|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 20:
			{{24|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x2afe38ab861ce41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{43|cuda_xor_r3_inv(39, 49, nr_bits_address_internal*2, 3)}}
			node1 *= 0xdf792e0ca5e01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{50|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{29|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 21:
			{{44|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x11e22dcd774701L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{50|cuda_xor_r3_inv(34, 48, nr_bits_address_internal*2, 3)}}
			node1 *= 0x36a0d8d37e9e601L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{31|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{38|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 22:
			{{8|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x358ac41663d0921L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{11|cuda_xor_r3_inv(23, 11, nr_bits_address_internal*2, 3)}}
			node1 *= 0xa7320f9e9cfd01L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{14|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 23:
			{{43|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x18e70c0e0a798c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{50|cuda_xor_r3_inv(29, 28, nr_bits_address_internal*2, 3)}}
			node1 *= 0x1a5d3987f4fc5c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{19|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{20|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 24:
			{{20|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x114d3af41ee9c381L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{39|cuda_xor_r3_inv(14, 32, nr_bits_address_internal*2, 3)}}
			node1 *= 0x2c334d4e37573c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{18|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{31|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 25:
			{{25|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0xb5b41ead3ee61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{18|cuda_xor_r3_inv(24, 50, nr_bits_address_internal*2, 3)}}
			node1 *= 0x343bd3492677c61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{35|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{26|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 26:
			{{17|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0xdd46cce498c601L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r3_inv(33, 41, nr_bits_address_internal*2, 3)}}
			node1 *= 0xb43892c16569e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{48|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 27:
			{{18|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x3e7f2be0c9cbf41L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{46|cuda_xor_r3_inv(43, 23, nr_bits_address_internal*2, 3)}}
			node1 *= 0x2a9e04101a91781L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{20|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{26|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 28:
			{{29|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x1bf68f79001a3c1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{10|cuda_xor_r3_inv(15, 49, nr_bits_address_internal*2, 3)}}
			node1 *= 0x5e966c19447561L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{12|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{32|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 29:
			{{49|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x11235df1f15f921L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{27|cuda_xor_r3_inv(45, 36, nr_bits_address_internal*2, 3)}}
			node1 *= 0x5e845710612d61L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{49|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{30|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 30:
			{{43|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x27940ca3c661161L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{12|cuda_xor_r3_inv(39, 34, nr_bits_address_internal*2, 3)}}
			node1 *= 0xe1cd6bed930441L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{17|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{28|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
		case 31:
			{{7|cuda_xor_r_inv(nr_bits_address_internal*2, 3)}}
			node1 *= 0x2bd62da95deb021L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{28|cuda_xor_r3_inv(39, 50, nr_bits_address_internal*2, 3)}}
			node1 *= 0xe61a0f027704e1L;
			node1 &= {{((nr_bits_address_internal*2)|pow2-1)|hexa}};
			{{10|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			{{47|cuda_xor_lr_inv(nr_bits_address_internal*2, 3)}}
			break;
	}
	return node1;
}

{% endif %}
// Initial bitmixer function.
inline __device__ uint64_t {% if compact_hash_table %}U{% endif %}HASH_INIT(nodetype node) {
	uint64_t node1 = xor_rot2_64((uint64_t) node, 38, 14);
	node1 ^= 0xD1B54A32D192ED03L;
	node1 *= 0xAEF17502108EF2D9L;
	return node1;
}

inline __device__ indextype {% if compact_hash_table %}U{% endif %}HASH(uint8_t id, uint64_t node) {
	uint64_t node1 = node;
	switch (id) {
		case 0:
			{{12|cuda_xor_lr(64, 3)}}
			{{37|cuda_xor_lr(64, 3)}}
			node1 *= 0xd1b549a75a913001L;
			{{43|cuda_xor_r3(31, 23, 3)}}
			node1 *= 0xdb4f0ad2012a3801L;
			{{28|cuda_xor_r(3)}}
			break;
		case 1:
			{{10|cuda_xor_lr(64, 3)}}
			{{35|cuda_xor_lr(64, 3)}}
			node1 *= 0xe19b01a4b9790801L;
			{{40|cuda_xor_r3(34, 19, 3)}}
			node1 *= 0xe60e2b7534e39801L;
			{{26|cuda_xor_r(3)}}
			break;
		case 2:
			{{14|cuda_xor_lr(64, 3)}}
			{{39|cuda_xor_lr(64, 3)}}
			node1 *= 0xe95e1e450c4a0001L;
			{{44|cuda_xor_r3(30, 15, 3)}}
			node1 *= 0xebedeec09311a001L;
			{{30|cuda_xor_r(3)}}
			break;
		case 3:
			{{13|cuda_xor_lr(64, 3)}}
			{{34|cuda_xor_lr(64, 3)}}
			node1 *= 0xedf84e880b907001L;
			{{39|cuda_xor_r3(33, 25, 3)}}
			node1 *= 0xefa23a45cfedf001L;
			{{28|cuda_xor_r(3)}}
			break;
		case 4:
			{{11|cuda_xor_lr(64, 3)}}
			{{35|cuda_xor_lr(64, 3)}}
			node1 *= 0xf10426bc3c049001L;
			{{23|cuda_xor_r3(30, 26, 3)}}
			node1 *= 0xf22eeccd9c67f001L;
			{{20|cuda_xor_r(3)}}
			break;
		case 5:
			{{15|cuda_xor_lr(64, 3)}}
			{{33|cuda_xor_lr(64, 3)}}
			node1 *= 0xf32e82653debe001L;
			{{41|cuda_xor_r3(36, 20, 3)}}
			node1 *= 0xf40ba356b4275801L;
			{{23|cuda_xor_r(3)}}
			break;
		case 6:
			{{34|cuda_xor_lr(64, 3)}}
			{{12|cuda_xor_lr(64, 3)}}
			node1 *= 0xf4ccd6e6806ab001L;
			{{38|cuda_xor_r3(42, 24, 3)}}
			node1 *= 0xf57716cb7624c001L;
			{{29|cuda_xor_r(3)}}
			break;
		case 7:
			{{23|cuda_xor_lr(64, 3)}}
			{{35|cuda_xor_lr(64, 3)}}
			node1 *= 0xf60e40dc166cc801L;
			{{26|cuda_xor_r3(46, 23, 3)}}
			node1 *= 0xf6955e9e8d598801L;
			{{26|cuda_xor_r(3)}}
			break;
		case 8:
			{{31|cuda_xor_lr(64, 3)}}
			{{34|cuda_xor_lr(64, 3)}}
			node1 *= 0xf70edc3d744ed001L;
			{{29|cuda_xor_r3(40, 20, 3)}}
			node1 *= 0xf77cb25898912801L;
			{{27|cuda_xor_r(3)}}
			break;
		case 9:
			{{24|cuda_xor_lr(64, 3)}}
			{{20|cuda_xor_lr(64, 3)}}
			node1 *= 0xf7e077f74f578001L;
			{{40|cuda_xor_r3(33, 25, 3)}}
			node1 *= 0xf83b82f6f35ba801L;
			{{30|cuda_xor_r(3)}}
			break;
		case 10:
			{{10|cuda_xor_lr(64, 3)}}
			{{19|cuda_xor_lr(64, 3)}}
			node1 *= 0xf88ee9a3839ce001L;
			{{26|cuda_xor_r3(46, 23, 3)}}
			node1 *= 0xf8db99901f3c8001L;
			{{28|cuda_xor_r(3)}}
			break;
		case 11:
			{{14|cuda_xor_lr(64, 3)}}
			{{30|cuda_xor_lr(64, 3)}}
			node1 *= 0xf922585980506801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{43|cuda_xor_r3(12, 26, 3)}}
			node1 *= 0xf963d3cf7e2a1801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{31|cuda_xor_r(3)}}
			break;
		case 12:
			{{19|cuda_xor_lr(64, 3)}}
			{{41|cuda_xor_lr(64, 3)}}
			node1 *= 0xf9a099bfb3022801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{24|cuda_xor_r3(39, 21, 3)}}
			node1 *= 0xf9d92a6f4ae93001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{25|cuda_xor_r(3)}}
			break;
		case 13:
			{{28|cuda_xor_lr(64, 3)}}
			{{15|cuda_xor_lr(64, 3)}}
			node1 *= 0xfa0deebd73767801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{32|cuda_xor_r3(40, 24, 3)}}
			node1 *= 0xfa3f47134b674001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{27|cuda_xor_r(3)}}
			break;
		case 14:
			{{43|cuda_xor_lr(64, 3)}}
			{{32|cuda_xor_lr(64, 3)}}
			node1 *= 0xfa6d875fe549e801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{31|cuda_xor_r3(46, 28, 3)}}
			node1 *= 0xfa98f6e7e6aa4001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{26|cuda_xor_r(3)}}
			break;
		case 15:
			{{35|cuda_xor_lr(64, 3)}}
			{{42|cuda_xor_lr(64, 3)}}
			node1 *= 0xfac1d3f253805801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{25|cuda_xor_r3(44, 29, 3)}}
			node1 *= 0xfae8596df8e0f801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{28|cuda_xor_r(3)}}
			break;
		case 16:
			{{35|cuda_xor_lr(64, 3)}}
			{{49|cuda_xor_lr(64, 3)}}
			node1 *= 0xfb0cb72e09912001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{20|cuda_xor_r3(29, 44, 3)}}
			node1 *= 0xfb2f1d5d45068801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{35|cuda_xor_r(3)}}
			break;
		case 17:
			{{45|cuda_xor_lr(64, 3)}}
			{{29|cuda_xor_lr(64, 3)}}
			node1 *= 0xfb4fb0e58fd21001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{15|cuda_xor_r3(44, 33, 3)}}
			node1 *= 0xfb6e96edd75cd001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{41|cuda_xor_r(3)}}
			break;
		case 18:
			{{20|cuda_xor_lr(64, 3)}}
			{{36|cuda_xor_lr(64, 3)}}
			node1 *= 0xfb8bf0f836eb0801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{21|cuda_xor_r3(41, 13, 3)}}
			node1 *= 0xfba7daea24511001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{34|cuda_xor_r(3)}}
			break;
		case 19:
			{{10|cuda_xor_lr(64, 3)}}
			{{8|cuda_xor_lr(64, 3)}}
			node1 *= 0xfbc26ee0b36f8801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{49|cuda_xor_r3(11, 34, 3)}}
			node1 *= 0xfbdbc52b8ed14001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{15|cuda_xor_r(3)}}
			break;
		case 20:
			{{29|cuda_xor_lr(64, 3)}}
			{{50|cuda_xor_lr(64, 3)}}
			node1 *= 0xfbf3f4486e688001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{43|cuda_xor_r3(39, 49, 3)}}
			node1 *= 0xfc0b0cfe69507001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{24|cuda_xor_r(3)}}
			break;
		case 21:
			{{38|cuda_xor_lr(64, 3)}}
			{{31|cuda_xor_lr(64, 3)}}
			node1 *= 0xfc2125faae868001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{50|cuda_xor_r3(34, 48, 3)}}
			node1 *= 0xfc364c4c4e6e4001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{44|cuda_xor_r(3)}}
			break;
		case 22:
			{{14|cuda_xor_lr(64, 3)}}
			{{49|cuda_xor_lr(64, 3)}}
			node1 *= 0xfc4a90f39b00c001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{11|cuda_xor_r3(23, 11, 3)}}
			node1 *= 0xfc5e011de66eb801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{8|cuda_xor_r(3)}}
			break;
		case 23:
			{{20|cuda_xor_lr(64, 3)}}
			{{19|cuda_xor_lr(64, 3)}}
			node1 *= 0xfc70aa0535529001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{50|cuda_xor_r3(29, 28, 3)}}
			node1 *= 0xfc8296fd443dd001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{43|cuda_xor_r(3)}}
			break;
		case 24:
			{{31|cuda_xor_lr(64, 3)}}
			{{18|cuda_xor_lr(64, 3)}}
			node1 *= 0xfc93d17169271001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{39|cuda_xor_r3(14, 32, 3)}}
			node1 *= 0xfca466baa09f2001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{20|cuda_xor_r(3)}}
			break;
		case 25:
			{{26|cuda_xor_lr(64, 3)}}
			{{35|cuda_xor_lr(64, 3)}}
			node1 *= 0xfcb45e62fe09e801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{18|cuda_xor_r3(24, 50, 3)}}
			node1 *= 0xfcc3bffadf4d6801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{25|cuda_xor_r(3)}}
			break;
		case 26:
			{{48|cuda_xor_lr(64, 3)}}
			{{49|cuda_xor_lr(64, 3)}}
			node1 *= 0xfcd2950bef268801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{28|cuda_xor_r3(33, 41, 3)}}
			node1 *= 0xfce0e33f22ce8001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{17|cuda_xor_r(3)}}
			break;
		case 27:
			{{26|cuda_xor_lr(64, 3)}}
			{{20|cuda_xor_lr(64, 3)}}
			node1 *= 0xfceeb42967ca2001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{46|cuda_xor_r3(43, 23, 3)}}
			node1 *= 0xfcfc0b896bf43001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{18|cuda_xor_r(3)}}
			break;
		case 28:
			{{32|cuda_xor_lr(64, 3)}}
			{{12|cuda_xor_lr(64, 3)}}
			node1 *= 0xfd08f2fd84bba801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{10|cuda_xor_r3(15, 49, 3)}}
			node1 *= 0xfd156c57a01b1001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{29|cuda_xor_r(3)}}
			break;
		case 29:
			{{30|cuda_xor_lr(64, 3)}}
			{{49|cuda_xor_lr(64, 3)}}
			node1 *= 0xfd217f49540da801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{27|cuda_xor_r3(45, 36, 3)}}
			node1 *= 0xfd2d2da9e732b801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{49|cuda_xor_r(3)}}
			break;
		case 30:
			{{28|cuda_xor_lr(64, 3)}}
			{{17|cuda_xor_lr(64, 3)}}
			node1 *= 0xfd3881260ec2f001L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{12|cuda_xor_r3(39, 34, 3)}}
			node1 *= 0xfd4379a53f94a801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{43|cuda_xor_r(3)}}
			break;
		case 31:
			{{47|cuda_xor_lr(64, 3)}}
			{{10|cuda_xor_lr(64, 3)}}
			node1 *= 0xfd4e1cef854fc801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{28|cuda_xor_r3(39, 50, 3)}}
			node1 *= 0xfd586eda2734f801L;
			node1 &= {{((64)|pow2-1)|hexa}};
			{{7|cuda_xor_r(3)}}
			break;
	}
	{% if compact_hash_table %}
	return 2*(node1 & {{(nr_bits_address_internal|pow2-1)|hexa}});
	{% elif nr_bits_address_root <= 32 %}
	return ((node1 & {{(nr_bits_address_root|pow2-1)|hexa}})*d_hash_table_size) >> {{nr_bits_address_root}};
	{% else %}
	{% if nr_bits_address_root < 64 %}
	node1 = node1 & {{(nr_bits_address_root|pow2-1)|hexa}};
	{% endif %}
	// We apply long multiplication, to avoid integer overflow. Overflow must be avoided to ensure the result is within the range [0,...,d_hash_table_size).
	{% if nr_bits_address_root < 64 %}
	uint32_t s0;
	{% endif %}
	uint32_t s1, s2, s3;
	uint64_t x = ((uint64_t) get_right(node1)) * ((uint64_t) get_right(d_hash_table_size));
	{% if nr_bits_address_root < 64 %}
	s0 = get_left(x);
	{% endif %}
	x = ((uint64_t) get_left(node1)) * ((uint64_t) get_right(d_hash_table_size)) + ((uint64_t) get_left(node1));
	s1 = get_right(x);
	s2 = get_left(x);
	x = ((uint64_t) s1) + ((uint64_t) get_right(node1)) * ((uint64_t) get_left(d_hash_table_size));
	s1 = get_right(x);
	x = ((uint64_t) s2) + ((uint64_t) get_left(node1)) * ((uint64_t) get_left(d_hash_table_size)) + ((uint64_t) get_left(x));
	s2 = get_right(x);
	s3 = get_left(x);
	// Carry.
	x = (uint64_t) s3;
	x = x << 32 | s2;
	{% if nr_bits_address_root < 64 %}
	// Result.
	node1 = (uint64_t) s1;
	node1 = node1 << 32 | s0;
	// Right shift to obtain final result.
	node1 = node1 >> {{nr_bits_address_root}};
	x = x << {{64-nr_bits_address_root}};
	node1 |= x;
	{% else %}
	node1 = x;
	{% endif %}
	return (indextype) node1;
	{% endif %}
}

{% if compact_hash_table %}
// Retrieve ID of used hash function from a compressed root vectortree node.
inline __device__ uint8_t get_hash_id_root(compressed_nodetype n) {
	uint8_t hid = (uint8_t) (n >> {{(2*nr_bits_address_internal)-nr_bits_address_root}});
	// Remove the 'new' flag.
	return (hid & 0x1F);
}

// Reconstruct uncompressed root vectortree node from the given compressed root vectortree node and the address at which it is stored in the global memory hash table.
inline __device__ nodetype get_uncompressed_node_root(compressed_nodetype n, indextype i) {
	nodetype e = (((nodetype) i) << {{(2*nr_bits_address_internal)-nr_bits_address_root}});
	// Obtain hash function ID.
	uint8_t hid = get_hash_id_root(n);
	// Remove five bits for hash function ID + one for 'new' flag.
	e |= (nodetype) (n & 0x03FFFFFF);
	// Retrieve uncompressed node and return it.
	e = HASH_INVERSE(hid, e);
	return RHASH_INIT_INVERSE(e);
}

// Extract a global memory internal hash table index from a given hash.
inline __device__ indextype get_index(nodetype h) {
	return (indextype) (h >> {{nr_bits_address_internal}});
}

// Construct from a hash and a hash function ID a compressed root vectortree node.
inline __device__ compressed_nodetype get_compressed_node_root(nodetype h, uint8_t hid) {
	compressed_nodetype e = (compressed_nodetype) hid;
	e = (e << {{(2*nr_bits_address_internal)-nr_bits_address_root}});
	// Mark the node as 'new'.
	e |= 0x80000000;
	e |= (compressed_nodetype) (h & {{((((2*nr_bits_address_internal)-nr_bits_address_root)|pow2)-1)|hexa}});
	return e;
}

{% endif %}
// Retrieve vectortree node at index i of the global memory hash table.
inline __host__ __device__ nodetype HT_RETRIEVE(compressed_nodetype *d_q, indextype i{% if compact_hash_table %}, indextype offset{% endif %}) {
	{% if not compact_hash_table %}
	return (nodetype) d_q[i];
	{% else %}
	if (offset != 0) {
		// We are retrieving a non-root node from the internal nodes table.
		return *(d_q+offset+(2*i));
	}
	else {
		// We are retrieving a root node from the root table.
		compressed_nodetype j = d_q[i];
		// Construct the complete element.
		return get_uncompressed_node_root(j, i);
	}
	{% endif %}
}

// Find or put a given vectortree node in the global hash table.
inline __device__ {% if nr_bits_address_root < 32 %}indextype{% else %}uint64_t{% endif %} FINDORPUT_SINGLE(compressed_nodetype *d_q, nodetype node, volatile uint8_t *d_newstate_flags{% if compact_hash_table %}, indextype offset{% endif %}, bool claim_work) {
	nodetype e1;
	{% if compact_hash_table %}
	nodetype e2;
	compressed_nodetype compressed_node;
	compressed_nodetype compressed_element;
	{% endif %}
	indextype addr;
	nodetype element;
	shared_inttype shared_addr;
	e1 = HASH_INIT(node);
	for (int i = 0; i < NR_HASH_FUNCTIONS; i++) {
		{% if compact_hash_table %}
		e2 = HASH(i, e1);
		addr = get_index(e2);
		if (offset == 0) {
			compressed_node = get_compressed_node_root(e2, i);
			// Special case: if the compressed node coincides with the value for an empty compressed node, continue
			if (compressed_node == EMPTY_COMPRESSED_NODE) {
				continue;
			}
			addr = HASH(i, node);
			compressed_element = d_q[addr];
			if (compressed_element == EMPTY_COMPRESSED_NODE) {
				compressed_element = atomicCAS(&(d_q[addr]), EMPTY_COMPRESSED_NODE, compressed_node);
				if (compressed_element == EMPTY_COMPRESSED_NODE) {
					// Successfully stored the node.
					// Try to claim the vector for future work. For this, try to increment the OPENTILECOUNT counter.
					if (claim_work && (shared_addr = atomicAdd((unsigned int*) &OPENTILECOUNT, 1)) < OPENTILELEN) {
						// Store pointer to root in the work tile.
						shared[OPENTILEOFFSET+shared_addr] = (shared_inttype) addr;
						// Mark the state as old in the hash table.
						atomicCAS(&(d_q[addr]), compressed_node, mark_old(compressed_node));
					}
					else {
						// There is work available for some block.
						d_newstate_flags[(addr / BLOCK_SIZE) % GRID_SIZE] = 1;
					}
					return addr;
				}
			}
			if (compressed_element == compressed_node) {
				// The node is already stored.
				return addr;
			}
		}
		else {
		{% else %}
			addr = HASH(i, e1);
		{% endif %}
			element = *(d_q+addr);
			if (element == EMPTY_NODE) {
				element = atomicCAS(&(d_q[{% if compact_hash_table %}offset+{% endif %}addr]), EMPTY_NODE, node);
				if (element == EMPTY_NODE) {
					// Successfully stored the node.
				{% if not compact_hash_table and vectorsize > 62 %}
					if (is_root(node)) {
				{% endif %}
					{% if not compact_hash_table %}
						// Try to claim the vector for future work. For this, try to increment the OPENTILECOUNT counter.
						if (claim_work && (shared_addr = atomicAdd((unsigned int*) &OPENTILECOUNT, 1)) < OPENTILELEN) {
							{% if vectorsize > 30 %}
							// Store pointer to root in the work tile.
							shared[OPENTILEOFFSET+shared_addr] = (shared_inttype) addr;
							{% else %}
							// Store the node in the work tile.
							shared[OPENTILEOFFSET+shared_addr] = node;
							{% endif %}
							// Mark the state as old in the hash table.
							atomicCAS(&(d_q[{% if compact_hash_table %}offset+{% endif %}addr]), node, mark_old(node));
						}
						else {
							// There is work available for some block.
							d_newstate_flags[(addr / BLOCK_SIZE) % GRID_SIZE] = 1;
						}
					{% endif %}
					{% if not compact_hash_table and vectorsize > 62 %}
					}
					{% endif %}
					return addr;
				}
			}
			if (element == node) {
				// The node is already stored.
				return addr;
			}
		{% if compact_hash_table %}
		}
		{% endif %}
	}
	// Error: hash table considered full.
	return HASHTABLE_FULL;
}

// Find or put all new vectortree nodes stored in the shared memory cache into the global memory hash table.
__device__ void FINDORPUT_MANY(compressed_nodetype *d_q, volatile uint8_t *d_newstate_flags) {
	nodetype node;
	indextype addr;
	{% if vectorsize > 62 %}
	shared_inttype node_pointers;
	shared_inttype node_pointers_child;
	bool work_to_do = false;

	if (THREAD_ID == 0) {
		CONTINUE = 0;
	}
	__syncthreads();
	for (shared_indextype i = THREAD_ID{% if vectorsize > 62 %}*3{% endif %}; i < d_shared_cache_size && CONTINUE != 2; i += BLOCK_SIZE{% if vectorsize > 62 %}*3{% endif %}) {
		node_pointers = shared[CACHEOFFSET+i+2];
		// Check if node is ready for storage. Only new leafs are ready at this point. We rely on old and new non-leafs having pointers with the highest
		// two bits set to zero, empty entries and old leafs having pointers set to zero, and new leafs having pointers set to 0x40000000.
		if (cache_pointers_are_marked_new_leaf(node_pointers)) {
			node = combine_halfs(shared[CACHEOFFSET+i], shared[CACHEOFFSET+i+1]);
			// Store node in hash table.
			addr = FINDORPUT_SINGLE(d_q, node, d_newstate_flags{% if compact_hash_table %}, d_non_root_offset{% endif %}, true);
			if (addr == HASHTABLE_FULL) {
				CONTINUE = 2;
			}
			else {
				// Store global memory address in cache.
				set_cache_pointers_to_global_address(&shared[CACHEOFFSET+i], addr);
			}
		}
		// Node is not ready yet. Check if it can be updated.
		else if (node_pointers != 0) {
			if (head_is_new(shared[CACHEOFFSET+i])) {
				node = combine_halfs(shared[CACHEOFFSET+i], shared[CACHEOFFSET+i+1]);
				if (vectortree_node_contains_left_gap(node)) {
					// Look up left child and check for presence of global memory address.
					node_pointers_child = sv_step(i, false);
					node_pointers_child = shared[CACHEOFFSET+node_pointers_child+2];
					if (cache_pointers_contain_global_address(node_pointers_child)) {
						set_left_in_vectortree_node(&node, node_pointers_child);
						// Copy back to shared memory.
						shared[CACHEOFFSET+i] = get_left(node);
						shared[CACHEOFFSET+i+1] = get_right[node];
					}
				}
				if (vectortree_node_contains_right_gap(node)) {
					// Look up right child and check for presence of global memory address.
					node_pointers_child = sv_step(i, true);
					node_pointers_child = shared[CACHEOFFSET+node_pointers_child+2];
					if (cache_pointers_contain_global_address(node_pointers_child)) {
						set_right_in_vectortree_node(&node, node_pointers_child);
						// Copy back to shared memory.
						shared[CACHEOFFSET+i] = get_left(node);
						shared[CACHEOFFSET+i+1] = get_right[node];
					}
				}
				// Ready now?
				if (!vectortree_node_contains_left_gap(node) && !vectortree_node_contains_right_gap(node)) {
					// Possibly reset new bit.
					if (!is_root(node)) {
						node = mark_non_root_old(node);
					}
					// Store node in hash table.
					addr = FINDORPUT_SINGLE(d_q, node, d_newstate_flags{% if compact_hash_table %}, (is_root(node) ? 0 : d_non_root_offset){% endif %}, true);
					if (addr == HASHTABLE_FULL) {
						CONTINUE = 2;
					}
					else {
						// Store global memory address in cache.
						set_cache_pointers_to_global_address(&(shared[CACHEOFFSET+i]), addr);
					}
				}
				else {
					work_to_do = true;
					CONTINUE = 1;
				}
			}
		}
	}
	__syncthreads();
	while (CONTINUE == 1) {
		if (THREAD_ID == 0) {
			CONTINUE = 0;
		}
		__syncthreads();
		if (work_to_do) {
			work_to_do = false;
			for (shared_indextype i = THREAD_ID*3; i < d_shared_cache_size; i += BLOCK_SIZE*3) {
				node_pointers_child = shared[CACHEOFFSET+i];
				// If the node is marked new, this is a node still to be processed.
				if (head_is_new(node_pointers_child)) {
					node_pointers = shared[CACHEOFFSET+i+2];
					// If this is a root node, processing is only required if the pointers do not contain a global address.
					if (!head_is_root(node_pointers_child) || !cache_pointers_contain_global_address(node_pointers)) {
						node = combine_halfs(shared[CACHEOFFSET+i], shared[CACHEOFFSET+i+1]);
						if (vectortree_node_contains_left_gap(node)) {
							// Look up left child and check for presence of global memory address.
							node_pointers_child = sv_step(i, false);
							node_pointers_child = shared[CACHEOFFSET+node_pointers_child+2];
							if (cache_pointers_contain_global_address(node_pointers_child)) {
								set_left_in_vectortree_node(&node, node_pointers_child);
								// Copy back to shared memory.
								shared[CACHEOFFSET+i] = get_left(node);
								shared[CACHEOFFSET+i+1] = get_right[node];
							}
						}
						if (vectortree_node_contains_right_gap(node)) {
							// Look up right child and check for presence of global memory address.
							node_pointers_child = sv_step(i, true);
							node_pointers_child = shared[CACHEOFFSET+node_pointers_child+2];
							if (cache_pointers_contain_global_address(node_pointers_child)) {
								set_right_in_vectortree_node(&node, node_pointers_child);
								// Copy back to shared memory.
								shared[CACHEOFFSET+i] = get_left(node);
								shared[CACHEOFFSET+i+1] = get_right[node];
							}
						}
						// Ready now?
						if (!vectortree_node_contains_left_gap(node) && !vectortree_node_contains_right_gap(node)) {
							// Possibly reset new bit.
							if (!is_root(node)) {
								node = mark_non_root_old(node);
							}
							// Store node in hash table.
							addr = FINDORPUT_SINGLE(d_q, node, d_newstate_flags{% if compact_hash_table %}, (is_root(node) ? 0 : d_non_root_offset){% endif %}, true);
							if (addr == HASHTABLE_FULL) {
								CONTINUE = 2;
							}
							else {
								// Store global memory address in cache.
								set_cache_pointers_to_global_address(&(shared[CACHEOFFSET+i]), addr);
							}
						}
						else {
							work_to_do = true;
							CONTINUE = 1;
						}
					}
				}
			}
		}
		__syncthreads();
	}
	{% else %}
	for (shared_indextype i = THREAD_ID; i < d_shared_cache_size && CONTINUE != 2; i += BLOCK_SIZE) {
		{% if vectorsize > 30 %}
		node = combine_halfs(shared[CACHEOFFSET+i], shared[CACHEOFFSET+i+1]);
		{% else %}
		node = shared[CACHEOFFSET+i];
		{% endif %}
		if (is_new(node)) {
			// Store node in hash table.
			addr = FINDORPUT_SINGLE(d_q, node, d_newstate_flags, true);
			if (addr == HASHTABLE_FULL) {
				CONTINUE = 2;
			}
		}
	}
	{% endif %}
}

// Kernel to store the initial state in the global memory hash table.
__global__ void store_initial_state(compressed_nodetype *d_q, volatile uint8_t *d_newstate_flags, shared_inttype *d_worktiles) {
{{cuda_initial_vector}}
	__syncthreads();
	FINDORPUT_MANY(d_q, d_newstate_flags);
	__syncthreads();
	// Done. Copy the work tile to global memory.
	if (THREAD_ID < OPENTILELEN+LASTSEARCHLEN) {
		d_worktiles[(OPENTILELEN+LASTSEARCHLEN+1)*BLOCK_ID + THREAD_ID] = shared[OPENTILEOFFSET+THREAD_ID];
	}
	if (THREAD_ID == 0) {
		d_worktiles[(OPENTILELEN+LASTSEARCHLEN+1)*BLOCK_ID + OPENTILELEN + LASTSEARCHLEN] = OPENTILECOUNT;
	}
}
{% if vectorsize > 62 %}

// Auxiliary functions for the fetching of vectortrees from the global hash table. They encode the distribution of vectortree nodes over the threads
// in a vectortree group, and their structural relations with each other.
inline __device__ uint8_t get_vectortree_leaf_parent_thread(uint8_t tid) {
	switch (tid) {
	{% for n in vectortree.keys() if vectortree[n] == [] %}
		case {{vectortree_leaf_thread[n]}}:
			return {{vectortree_T[n]}};
			break;
	{% endfor %}
		default:
			return {{vectortree.keys()|length}};
			break;
	}
}

inline __device__ uint8_t get_vectortree_nonleaf_parent_thread(uint8_t tid) {
	switch (tid) {
	{% for n in vectortree.keys() if vectortree[n] != [] and n > 0 %}
		case {{n}}:
			return {{vectortree_T[n]}};
			break;
	{% endfor %}
		default:
			return {{vectortree.keys()|length}};
			break;
	}
}

inline __device__ uint8_t get_vectortree_nonleaf_left_child_thread(uint8_t tid) {
	switch (tid) {
	{% for n in vectortree.keys() if vectortree[n] != [] %}
		case {{n}}:
			return {% if vectortree[vectortree[n][0]] != [] %}{{vectortree[n][0]}}{% else %}{{vectortree_leaf_thread[vectortree[n][0]]}}{% endif %};
			break;
	{% endfor %}
		default:
			return {{vectortree.keys()|length}};
			break;
	}
}

inline __device__ uint8_t get_vectortree_nonleaf_right_child_thread(uint8_t tid) {
	switch (tid) {
	{% for n in vectortree.keys() if vectortree[n]|length == 2 %}
		case {{n}}:
			return {% if vectortree[vectortree[n][1]] != [] %}{{vectortree[n][1]}}{% else %}{{vectortree_leaf_thread[vectortree[n][1]]}}{% endif %};
			break;
	{% endfor %}
		default:
			return {{vectortree.keys()|length}};
			break;
	}
}
{% if not no_smart_fetching %}

// Auxiliary functions to obtain bitmasks for smart vectortree fetching based on the states of the state machines.
// Given a vector tree node id, return a bitmask expressing which vectorparts are reachable from the node.
inline __device__ uint32_t get_part_reachability(vectornode_indextype nid) {
	switch (nid) {
		{% for i in range(0,vectortree|length) %}
		case {{i}}:
			return {{smart_vectortree_fetching_bitmask[i]}};
		{% endfor %}
		default:
			return 0;
	}
}

// Functions to obtain a bitmask for a given state machine state that indicates which vectorparts are of interest to process outgoing transitions
// of that state.
{% for i in range(0, smnames|length) %}
inline __device__ uint32_t get_part_bitmask_{{state_order[i]|replace("'","_")}}(statetype sid) {
	switch (sid) {
		{% for s in smname_to_object[state_order[i]][1].states %}
		{% set o = smname_to_object[state_order[i]][0] %}
		{% if s|nr_of_transitions_to_be_processed_by(i,o) > 0 %}
		case {{state_id[s]}}:
			return {{s|get_smart_fetching_vectorparts_bitmask(o)}};
		{% endif %}
		{% endfor %}
		default:
			return 0;
	}
}
{% endfor %}

// Function to construct a bitmask for smart fetching, based on the given vectorparts.
inline __device__ uint32_t get_part_bitmask_for_states_in_vectorpart(uint8_t pid, nodetype part1, nodetype part2) {
	uint32_t result = 0x0;
	statetype s;
	switch (pid) {
		{% for i in range(0, vectorstructure|length) %}
		case {{i}}:
			{% for j in range(0, state_order|length) %}
			{% set PIDs = vectorelem_in_structure_map[state_order[j]] %}
			{% if PIDs[1][0] == i %}
			result = result | get_part_bitmask_{{state_order[j]|replace("'","_")}}(get_{{state_order[j]|replace("'","_")}}(&s, part1, part2));
			{% endif %}
			{% endfor %}
			return result;
		{% endfor %}
		default:
			return result;
	}
}
{% endif %}

// Retrieve a vectortree from the global hash table and store it in the cache. This is performed in a warp-centric way.
// Address addr points to the root of the requested vectortree. The function returns the address of the root of the vectortree in the cache,
// or HASHTABLE_FULL in the case the cache is full.
inline __device__ shared_indextype FETCH(thread_group treegroup, compressed_nodetype *d_q, indextype addr) {
	nodetype node = 0;
	{% if vectorsize > 62 %}
	nodetype leaf_node = 0;
	nodetype node_tmp_1 = 0;
	nodetype node_tmp_2 = 0;
	indextype node_addr = 0;
	shared_inttype cache_pointers = 0;
	shared_inttype result;
	shared_indextype cache_addr = 0;
	shared_indextype cache_addr_child = 0;
	uint8_t gid = treegroup.thread_rank();
	uint8_t target_thread_id;
	{% if not no_smart_fetching %}
	uint32_t smart_fetching_bitmask = 0x0;
	{% endif %}
	
	if (gid == 0) {
		node = HT_RETRIEVE(d_q, addr{% if compact_hash_table %}, 0{% endif %});
		node_tmp_1 = node;
	}
	{% set bound = 1 %}{% if not no_smart_fetching %}{% set bound = bound + 1 %}{% endif %}
	{% for j in range(0, bound) %}
	{% for i in range(1, vectortree_depth) %}
	{% set lsize = vectortree_level_ids[i]|length %}
	{% set lfirst = vectortree_level_ids[i][0] %}
	{% set llast = vectortree_level_ids[i][vectortree_level_ids[i]|length - 1] %}
	// Obtain node from vectortree parent.
	target_thread_id = {{vectortree.keys()|length}};
	{% if vectortree_level_nr_of_leaves[i] == lsize %}
	if (gid >= {{vectortree_leaf_thread[lfirst]}} && gid <= {{vectortree_leaf_thread[llast]}}) {
		target_thread_id = get_vectortree_leaf_parent_thread(gid);
	}
	{% elif vectortree_level_nr_of_leaves[i] > 0 %}
	if ({% for n in vectortree_level_ids[i] if vectortree[n]|length == 0 %}gid == {{vectortree_leaf_thread[n]}}{% if not loop.last %} || {% endif %}{% endfor %}) {
		target_thread_id = get_vectortree_leaf_parent_thread(gid);
	}
	{% endif %}
	{% if vectortree_level_nr_of_leaves[i] < lsize %}
	{% if vectortree_level_nr_of_leaves[i] > 0 %}	else {% else %}	{% endif %}if (gid >= {{lfirst}} && gid <= {{llast}}) {
		target_thread_id = gid;
	}
	{% endif %}
	treegroup.sync();
	node_tmp_2 = treegroup.shfl(node_tmp_1, target_thread_id);
	// Process the received node, if applicable.
	if (target_thread_id != {{vectortree.keys()|length}}) {
		node_addr = get_pointer_from_vectortree_node(node_tmp_2, false{% for n in vectortree_level_ids[i] if (vectortree[vectortree_T[n]]|length == 2 and vectortree[vectortree_T[n]][vectortree[vectortree_T[n]]|length-1] == n) %} || gid == {% if vectortree[n] == [] %}{{get_vectortree_leaf_parent_thread[n]}}{% else %}{{n}}{% endif %}{% endfor %});	
	{% if vectortree_level_nr_of_leaves[i] == lsize %}
		{% if not no_smart_fetching %}
		if (({% if j == 0 %}{{smart_vectortree_fetching_bitmask[0]}}{% else %}smart_fetching_bitmask{% endif %} & (1 << (31-gid))) != 0x0) {
			leaf_node = HT_RETRIEVE(d_q, node_addr);
			// Store the leaf node in the cache.
			cache_pointers = 0;
			result = STOREINCACHE(leaf_node, cache_pointers);
			if (result == CACHE_FULL) {
				return CACHE_FULL;
			}
			else {
				cache_addr = (shared_indextype) result;
			}
		}
		{% else %}
		leaf_node = HT_RETRIEVE(d_q, node_addr);
		// Store the leaf node in the cache.
		cache_pointers = 0;
		cache_addr = STOREINCACHE(leaf_node, cache_pointers);
		{% endif %}
	{% elif vectortree_level_nr_of_leaves[i] > 0 %}
		if ({% for n in vectortree_level_ids[i] if vectortree[n]|length == 0 %}gid == {{vectortree_leaf_thread[n]}}{% if not loop.last %} || {% endif %}{% endfor %}) {
			{% if not no_smart_fetching %}
			if (({% if j == 0 %}{{smart_vectortree_fetching_bitmask[0]}}{% else %}smart_fetching_bitmask{% endif %} & (1 << (31-gid))) != 0x0) {
				leaf_node = HT_RETRIEVE(d_q, node_addr);
				// Store the leaf node in the cache.
				cache_pointers = 0;
				result = STOREINCACHE(leaf_node, cache_pointers);
				if (result == CACHE_FULL) {
					return CACHE_FULL;
				}
				else {
					cache_addr = (shared_indextype) result;
				}
			}
			{% else %}
			leaf_node = d_q[node_addr];
			// Store the leaf node in the cache.
			cache_pointers = 0;
			result = STOREINCACHE(leaf_node, cache_pointers);
			if (result == CACHE_FULL) {
				return CACHE_FULL;
			}
			else {
				cache_addr = (shared_indextype) result;
			}
			{% endif %}
		}
		else {
			{% if not no_smart_fetching and j == 1 %}
			if (node == 0 && ({% if j == 0 %}{{smart_vectortree_fetching_bitmask[0]}}{% else %}smart_fetching_bitmask{% endif %} & get_part_reachability(gid)) != 0x0) {
				node = HT_RETRIEVE(d_q, node_addr);
				node_tmp_1 = node;
			}
			{% else %}
			node = HT_RETRIEVE(d_q, node_addr);
			node_tmp_1 = node;
			{% endif %}
		}
	{% else %}
		{% if not no_smart_fetching and j == 1 %}
		if (node == 0 && ({% if j == 0 %}{{smart_vectortree_fetching_bitmask[0]}}{% else %}smart_fetching_bitmask{% endif %} & get_part_reachability(gid)) != 0x0) {
			node = HT_RETRIEVE(d_q, node_addr);
			node_tmp_1 = node;
		}
		{% else %}
		node = HT_RETRIEVE(d_q, node_addr);
		node_tmp_1 = node;
		{% endif %}
	{% endif %}
	}
	{% endfor %}
	{% if not no_smart_fetching and j == 0 %}
	// Fetch the vectorpart to the right.
	node_tmp_1 = leaf_node;
	treegroup.sync();
	if (cache_addr != 0) {
		node_tmp_2 = treegroup.shfl(node_tmp_1, gid+1);
	}
	// Construct smart fetching bitmask.
	smart_fetching_bitmask = get_part_bitmask_for_states_in_vectorpart(gid, leaf_node, node_tmp_2);
	// Now merge all results of the different threads, resulting in the final bitmask.
	treegroup.sync();
	for (target_thread_id = treegroup.size()/2; target_thread_id > 0; target_thread_id /= 2) {
		smart_fetching_bitmask = smart_fetching_bitmask | treegroup.shfl_xor(smart_fetching_bitmask, target_thread_id);
	}
	// Finally discard the previously retrieved vectorpart ids from the bitmask.
	smart_fetching_bitmask = smart_fetching_bitmask & ~({{smart_vectortree_fetching_bitmask[0]}});
	// Set node_tmp_1 back to retrieved node.
	if (node != 0) {
		node_tmp_1 = node;
	}
	{% elif not no_smart_fetching and j == 1 %}
	// Add the initially retrieved vectorpart ids to the bitmask.
	smart_fetching_bitmask = smart_fetching_bitmask | {{smart_vectortree_fetching_bitmask[0]}};
	{% endif %}
	{% endfor %}
	cache_pointers = 0;
	{% for i in range(0, vectortree_depth-1)|reverse %}
	{% set lsize = vectortree_level_ids[i]|length %}
	{% set lfirst = vectortree_level_ids[i][0] %}
	{% set llast = vectortree_level_ids[i][vectortree_level_ids[i]|length - 1] %}
	// Obtain cache address for left child.
	target_thread_id = {{vectortree.keys()|length}};
	{% if vectortree_level_nr_of_leaves[i] == 0 %}
	if (gid >= {{lfirst}} && gid <= {{llast}}) {
		{% if not no_smart_fetching %}
		if ((smart_fetching_bitmask & get_part_reachability(gid)) != 0x0) {
			target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		}
		{% else %}
		target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		{% endif %}
	}
	{% elif vectortree_level_nr_of_leaves[i] < lsize %}
	if ({% for n in vectortree_level_ids[i] if vectortree[n]|length > 0 %}gid == {{n}}{% if not loop.last %} || {% endif %}{% endfor %}) {
		{% if not no_smart_fetching %}
		if ((smart_fetching_bitmask & get_part_reachability(gid)) != 0x0) {
			target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		}
		{% else %}
		target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		{% endif %}
	}
	{% endif %}
	treegroup.sync();
	cache_addr_child = treegroup.shfl(cache_addr, target_thread_id);
	// Set the received cache pointer.
	if (target_thread_id != {{vectortree.keys()|length}}) {
		set_left_cache_pointer(&cache_pointers, cache_addr_child);
	}
	{% if vectortree_level_nr_of_nodes_with_two_children[i] > 0 %}
	// Obtain cache address for right child.
	target_thread_id = {{vectortree.keys()|length}};
	{% if vectortree_level_nr_of_nodes_with_two_children[i] == lsize %}
	if (gid >= {{lfirst}} && gid <= {{llast}}) {
		{% if not no_smart_fetching %}
		if ((smart_fetching_bitmask & get_part_reachability(gid)) != 0x0) {
			target_thread_id = get_vectortree_nonleaf_right_child_thread(gid);
		}
		{% else %}
		target_thread_id = get_vectortree_nonleaf_right_child_thread(gid);
		{% endif %}
	}
	{% else %}
	if ({% for n in vectortree_level_ids[i] if vectortree[n]|length == 2 %}gid == {{n}}{% if not loop.last %} || {% endif %}{% endfor %}) {
		{% if not no_smart_fetching %}
		if ((smart_fetching_bitmask & get_part_reachability(gid)) != 0x0) {
			target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		}
		{% else %}
		target_thread_id = get_vectortree_nonleaf_left_child_thread(gid);
		{% endif %}
	}
	{% endif %}
	treegroup.sync();
	cache_addr_child = treegroup.shfl(cache_addr, target_thread_id);
	// Set the received cache pointer.
	if (target_thread_id != {{vectortree.keys()|length}}) {
		set_right_cache_pointer(&cache_pointers, cache_addr_child);
	}
	{% endif %}
	// Store the non-leaf node in the cache.
	{% if vectortree_level_nr_of_leaves[i] == 0 %}
	if (gid >= {{lfirst}} && gid <= {{llast}}) {
	{% else %}
	if ({% for n in vectortree_level_ids[i] if vectortree[n]|length > 0 %}gid == {{n}}{% if not loop.last %} || {% endif %}{% endfor %}) {
	{% endif %}
		{% if not no_smart_fetching %}
		if ((smart_fetching_bitmask & get_part_reachability(gid)) != 0x0) {
			node = mark_non_root_old(node);
			result = STOREINCACHE(leaf_node, cache_pointers);
			if (result == CACHE_FULL) {
				return CACHE_FULL;
			}
			else {
				cache_addr = (shared_indextype) result;
			}
		}
		{% else %}
		node = mark_non_root_old(node);
		result = STOREINCACHE(leaf_node, cache_pointers);
		if (result == CACHE_FULL) {
			return CACHE_FULL;
		}
		else {
			cache_addr = (shared_indextype) result;
		}
		{% endif %}
	}
	treegroup.sync();
	{% endfor %}
	{% else %}
	node = HT_RETRIEVE(d_q, node_addr{% if compact_hash_table %}, 0){% endif %});
	result = STOREINCACHE(leaf_node, cache_pointers);
	if (result == CACHE_FULL) {
		return CACHE_FULL;
	}
	else {
		cache_addr = (shared_indextype) result;
	}
	{% endif %}
	// Obtain cache address of the root and return it.
	cache_addr_child = treegroup.shfl(cache_addr, 0);
	return cache_addr_child;
}
{% endif %}

// *** END KERNELS AND FUNCTIONS FOR {% if vectorsize > 62 %}VECTOR TREE {% endif %}NODE STORAGE AND RETRIEVAL TO/FROM THE GLOBAL MEMORY HASH TABLE ***

// *** START FUNCTIONS FOR MODEL DATA RETRIEVAL AND STORAGE ***

// GPU data retrieval functions. Retrieve particular state info from the given state vector part(s).
// Precondition: the given parts indeed contain the requested info.
{% for s in vectorelem_in_structure_map.keys() %}
{% set size = vectorelem_in_structure_map[s][0] %}
inline __device__ void get_{{s|replace("[","_")|replace("]","")|replace("'","_")}}({% if s|is_state %}statetype{% elif size == 1 %}elem_booltype{% elif size < 32 %}elem_chartype{% else %}elem_inttype{% endif %} *b, nodetype part1, nodetype part2) {
{% if size < 16 %}
	uint16_t t2;
{% endif %}
	asm("{\n\t"
		" .reg .u{% if vectorsize < 31 %}32{% else %}64{% endif %} t1;\n\t"
{% if vectorelem_in_structure_map[s]|length == 2 %}
		" bfe.u{% if vectorsize < 31 %}32{% else %}64{% endif %} t1, %1, {{vectorelem_in_structure_map[s][1][1]}}, {{vectorelem_in_structure_map[s][1][2]}};\n\t"
{% else %}
		" bfe.u{% if vectorsize < 31 %}32{% else %}64{% endif %} t1, %2, {{vectorelem_in_structure_map[s][2][1]}}, {{vectorelem_in_structure_map[s][2][2]}};\n\t"
		" bfi.b{% if vectorsize < 31 %}32{% else %}64{% endif %} t1, %1, t1, {{vectorelem_in_structure_map[s][2][2]}}, {{vectorelem_in_structure_map[s][1][2]}};\n\t"
{% endif %}
		" cvt.u{% if size < 32 %}16{% else %}32{% endif %}.u{% if vectorsize < 31 %}32{% else %}64{% endif %} %0, t1;\n\t"
	    "}" : "={% if size < 16 %}h"(t2){% else %}r"(*b){% endif %} : "{% if vectorsize <= 30 %}r{% else %}l{% endif %}"(part1), "{% if vectorsize <= 30 %}r{% else %}l{% endif %}"(part2));
{% if size < 16 %}
	{% if s|is_state %}
	*b = (statetype) t2;
	{% elif size == 1 %}
	*b = (elem_booltype) t2;
	{% else %}
	*b = (elem_chartype) t2;
	{% endif %}
{% endif %}
}

{% endfor %}
{% if arraynames|length > 0 %}
// Data retrieval functions, including the fetching of required vector parts, for array elements with dynamic indexing.
{% for vname, t, size in arraynames %}
inline __device__ void get_{{vname|replace("[","_")|replace("]","")|replace("'","_")}}(shared_indextype node_index, {% if t|gettypesize == 1 %}elem_booltype{% elif t|gettypesize < 32 %}elem_chartype{% else %}elem_inttype{% endif %} *b, array_indextype index) {
	nodetype part1, part2;
	switch (index) {
		{% for i in range(0, size) %}
		case {{i}}:
			// Retrieve correct vector part(s).
			{% set PIDs = vectorelem_in_structure_map[vname + "[" + i|string + "]"] %}
			part1 = get_vectorpart_{{PIDs[1][0]}}(node_index);
			{% if PIDs|length > 2 %}
			part2 = get_vectorpart_{{PIDs[2][0]}}(node_index);
			{% endif %}
			// Get the data.
			get_{{vname|replace("[","_")|replace("]","") + "_" + i|string}}(b, part1, part2);
			break;
		{% endfor %}
		default:
			break;
	}
}

{% endfor %}
{% endif %}
// Retrieval of current state of state machine at position i in state vector.
inline __device__ void get_current_state(statetype *b, shared_indextype node_index, uint8_t i) {
	nodetype part1 = 0;
	nodetype part2 = 0;
	switch (i) {
		{% for i in range(0,smnames|length) %}
		case {{i}}:
			{% set vinfo = vectorelem_in_structure_map[state_order[i]] %}
			part1 = get_vectorpart_{{vinfo[1][0]}}(node_index);
			{% if vinfo|length > 2 %}
			part2 = get_vectorpart_{{vinfo[2][0]}}(node_index);
			{% endif %}
			get_{{state_order[i]|replace("'","_")}}(b, part1, part2);
			break;
		{% endfor %}
		default:
			break;
	}
}

// CPU data retrieval functions. Retrieve particular state info from the given state vector part(s).
// Precondition: the given parts indeed contain the requested info.
{% for s in vectorelem_in_structure_map.keys() %}
{% set size = vectorelem_in_structure_map[s][0] %}
inline void host_get_{{s|replace("[","_")|replace("]","")|replace("'","_")}}({% if s|is_state %}statetype{% elif size == 1 %}elem_booltype{% elif size < 32 %}elem_chartype{% else %}elem_inttype{% endif %} *b, nodetype part1, nodetype part2) {
	nodetype t1 = part1;
	{% if vectorelem_in_structure_map[s]|length == 2 %}
	// Strip away data beyond the requested data.
	t1 = t1 & {{((vectorelem_in_structure_map[s][1][1]+vectorelem_in_structure_map[s][1][2])|pow2-1)|hexa}};
	// Right shift to isolate requested data.
	t1 = t1 >> {{vectorelem_in_structure_map[s][1][1]}};
	{% else %}
	nodetype t2 = part2;
	// Strip away data beyond the requested data.
	t2 = t2 & {{((vectorelem_in_structure_map[s][2][1]+vectorelem_in_structure_map[s][2][2])|pow2-1)|hexa}};
	// Right shift to isolate requested data.
	t2 = t2 >> vectorelem_in_structure_map[s][2][1];
	// Isolate requested data.
	t1 = t1 & {{((vectorelem_in_structure_map[s][1][2])|pow2-1)|hexa}};
	// Move to integrate with first part.
	t1 = t1 << vectorelem_in_structure_map[s][2][2];
	t1 = t1 | t2;
	{% endif %}
	*b = ({% if s|is_state %}statetype{% elif size == 1 %}elem_booltype{% elif size < 32 %}elem_chartype{% else %}elem_inttype{% endif %}) t1;
}

{% endfor %}
{% if arraynames|length > 0 %}
// Data retrieval functions, including the fetching of required vector parts, for array elements with dynamic indexing.
{% for vname, t, size in arraynames %}
inline void host_get_{{vname|replace("[","_")|replace("]","")|replace("'","_")}}(shared_indextype node_index, {% if t|gettypesize == 1 %}elem_booltype{% elif t|gettypesize < 32 %}elem_chartype{% else %}elem_inttype{% endif %} *b, array_indextype index) {
	nodetype part1, part2;
	switch (index) {
		{% for i in range(0, size) %}
		case {{i}}:
			// Retrieve correct vector part(s).
			{% set PIDs = vectorelem_in_structure_map[vname + "[" + i|string + "]"] %}
			part1 = get_vectorpart_{{PIDs[1][0]}}(node_index);
			{% if PIDs|length > 2 %}
			part2 = get_vectorpart_{{PIDs[2][0]}}(node_index);
			{% endif %}
			// Get the data.
			host_get_{{vname|replace("[","_")|replace("]","") + "_" + i|string}}(b, part1, part2);
			break;
		{% endfor %}
		default:
			break;
	}
}

{% endfor %}
{% endif %}

// GPU data update functions. Update particular state info in the given state vector part(s).
// Precondition: the given part indeed needs to contain the indicated fragment (left or right in case the info is split over two parts) of the updated info.
{% for s in vectorelem_in_structure_map.keys() %}
{% set size = vectorelem_in_structure_map[s][0] %}
inline __device__ void set_left_{{s|replace("[","_")|replace("]","")|replace("'","_")}}(nodetype *part, {% if size == 1 %}elem_booltype{% elif size < 32 %}elem_chartype{% else %}elem_inttype{% endif %} x) {
	nodetype t1 = (nodetype) x;
	asm("{\n\t"
{% if vectorelem_in_structure_map[s]|length > 2 %}
		" shr.b{% if vectorsize < 31 %}32{% else %}64{% endif %} %1, %1, {{vectorelem_in_structure_map[s][2][2]}};\n\t"
{% endif %}
		" bfi.b{% if vectorsize < 31 %}32{% else %}64{% endif %} %0, %1, %0, {{vectorelem_in_structure_map[s][1][1]}}, {{vectorelem_in_structure_map[s][1][2]}};\n\t"
		"}" : "+{% if vectorsize <= 30 %}r{% else %}l{% endif %}"(*part) : "{% if vectorelem_in_structure_map[s]|length > 2 %}+{% endif %}{% if vectorsize <= 30 %}r{% else %}l{% endif %}"(t1));
}

{% if vectorelem_in_structure_map[s]|length > 2 %}
inline __device__ void set_right_{{s|replace("[","_")|replace("]","")|replace("'","_")}}(nodetype *part, {% if size == 1 %}elem_booltype{% elif size < 32 %}elem_chartype{% else %}elem_inttype{% endif %} x) {
	nodetype t1 = (nodetype) x;
	asm("{\n\t"
		" bfi.b{% if vectorsize < 31 %}32{% else %}64{% endif %} %0, t1, %0, {{vectorelem_in_structure_map[s][2][1]}}, {{vectorelem_in_structure_map[s][2][2]}};\n\t"
		"}" : "+l"(*part) : "r"(x));
}

{% endif %}
{% endfor %}
{% for x in dynamic_write_arrays.keys() %}
{% if loop.first %}
// Data update functions for arrays with dynamic indexing, focussed on one specific vector part.
{% endif %}
// Auxiliary functions for {{dynamic_write_arrays[x][0]}}.
inline __device__ bool array_element_is_in_vectorpart_{{dynamic_write_arrays[x][0]|replace("'","_")}}(array_indextype i, vectornode_indextype pid) {
	switch (pid) {
		{% for p in range(dynamic_write_arrays[x][1], dynamic_write_arrays[x][2]+1) %}
		case {{p}}:
			return (i >= {{(x|get_array_range_in_vectorpart(dynamic_write_arrays[x][0],p))[0]}} && i <= {{(x|get_array_range_in_vectorpart(dynamic_write_arrays[x][0],p))[1]}});
		{% endfor %}
		default:
			return false;
	}
}

// Precondition: array element i is (partially) stored in vector part pid.
inline __device__ bool is_left_vectorpart_for_array_element_{{dynamic_write_arrays[x][0]|replace("'","_")}}(array_indextype i, vectornode_indextype pid) {
	switch (pid) {
		{% for p in range(dynamic_write_arrays[x][1], dynamic_write_arrays[x][2]+1) %}
		case {{p}}:
			return (i >{% if loop.first %}= 0{% else %} {{(x|get_array_range_in_vectorpart(dynamic_write_arrays[x][0],p-1))[1]}}{% endif %} && i <= {{(x|get_array_range_in_vectorpart(dynamic_write_arrays[x][0],p))[1]}});
		{% endfor %}
		default:
			return false;
	}	
}

// Data update function for {{dynamic_write_arrays[x][0]}}.
inline __device__ void set_{{dynamic_write_arrays[x][0]|replace("'","_")}}(nodetype *part, array_indextype indices, {{x.type|cudatype(True)}} buf, buffer_indextype buf_offset, vectornode_indextype part_id) {
	if (part_id >= {{dynamic_write_arrays[x][1]}} && part_id <= {{dynamic_write_arrays[x][2]}}) {
		for (array_indextype i = 0;; i++) {
			if (indices[i] == EMPTY_INDEX) {
				break;
			}
			if (array_element_is_in_vectorpart_{{dynamic_write_arrays[x][0]|replace("'","_")}}(indices[i], part_id)) {
				if (is_left_vectorpart_for_array_element_{{dynamic_write_arrays[x][0]|replace("'","_")}}(indices[i], part_id)) {
					switch (indices[i]) {
						{% for i in range(dynamic_write_arrays[x][1], dynamic_write_arrays[x][2]+1) %}
						case {{i}}:
							set_left_{{dynamic_write_arrays[x][0]|replace("'","_")}}_{{i}}(part, buf[buf_offset + i]);
							break;
						{% endfor %}
						default:
							break;
					}
				}
				else {
					switch (indices[i]) {
						{% for i in range(dynamic_write_arrays[x][1], dynamic_write_arrays[x][2]+1) %}
						{% if vectorelem_in_structure_map[dynamic_write_arrays[x][0] + "[" + i|string + "]"]|length > 2 %}
						case {{i}}:
							set_right_{{dynamic_write_arrays[x][0]|replace("'","_")}}_{{i}}(part, buf[buf_offset + i]);
							break;
						{% endif %}
						{% endfor %}
						default:
							break;
					}
				}
			}
		}
	}
}
{% endfor %}

{% for c in model.channels|select("is_async") %}
{% if loop.first %}
// Data update functions for channel buffers, focussed on one specific vector part.
{% endif %}
// Data update function for parameter i of tail element of the buffer of {{c.name}}.
{% for i in range(0,c.type|length+1) %}
{% if i > 0 or signalsize[c] > 0 %}
inline __device__ void set_buffer_tail_element_{{c.name}}_{{i}}(nodetype *part, buffer_indextype size, {% if i == 0 %}{% if signalsize[c] <= 8 %}uint8_t{% elif signalsize[c] <= 16 %}uint16_t{% else %}uint32_t{% endif %}{% else %}{{(c.type[i-1])|cudatype(True)}}{% endif %} value, vectornode_indextype part_id) {
	switch (size) {
		{% for n in range(0,c.size) %}
		case {{n}}:
			switch (part_id) {
				{% set PIDs = vectorelem_in_structure_map.get(c.name + "[" + i|string + "][" + n|string + "]") %}
				{% if PIDs != None %}
				case {{PIDs[1][0]}}:
					set_left_{{c.name}}_{{i}}_{{n}}(part, value);
					break;
				{% if PIDs|length > 2 %}
				case {{PIDs[2][0]}}:
					set_right_{{c.name}}_{{i}}_{{n}}(part, value);
					break;
				{% endif %}
				{% endif %}
				default:
					break;
			}
		{% endfor %}
		default:
			break;
	}
}

{% endif %}
{% endfor %}
// Data update function shifting each element of the buffer of {{c.name}} one position towards the head, insofar this is relevant for the given vectorpart.
inline __device__ void shift_buffer_tail_elements_{{c.name}}(shared_indextype node_index, shared_inttype *part, buffer_indextype size, vectornode_indextype part_id) {
	{% if c.size > 1 %}
	nodetype part_tmp;
	{% if signalsize[c] > 0 %}
	{% if signalsize <= 2 %}
	bool signal_tmp;
	{% elif signalsize <= 8 %}
	uint8_t signal_tmp;
	{% elif signalsize <= 16 %}
	uint16_t signal_tmp;
	{% elif signalsize <= 32 %}
	uint32_t signal_tmp;
	{% endif %}
	{% endif %}
	{% for t in c.type %}
	{% if t.base == 'Integer' %}
	elem_inttype int_tmp;{{break}}
	{% endif %}
	{% endfor %}
	{% for t in c.type %}
	{% if t.base == 'Byte' %}
	elem_chartype char_tmp;{{break}}
	{% endif %}
	{% endfor %}
	{% for t in c.type %}
	{% if t.base == 'Boolean' %}
	elem_booltype bool_tmp;{{break}}
	{% endif %}
	{% endfor %}

	switch (part_id) {
		{% set parts = async_channel_vectorpart_buffer_range[c] %}
		{% for p in parts.keys() %}
		case {{p}}:
			{% if parts.get(p+1) != None %}
			part_tmp = get_vectorpart(node_index, part_id+1);
			{% endif %}
			{% set lower1 = parts[p][0][0] %}
			{% set lower2 = parts[p][0][1] %}
			{% set upper1 = parts[p][1][0] %}
			{% set upper2 = parts[p][1][1] %}
			{% for i in range(0,c.size) %}
			{% for j in range(0,c.type|length+1) %}
			{% if (lower2 < i or (lower2 == i and lower1 <= j)) and (upper2 > i or (upper2 == i and upper1 >= j)) and c|next_buffer_element(j,i) != (-1,-1) and (j > 0 or signalsize[c] > 0) %}
			if ({{i+1}} < size) {
			{% set (nj,ni) = c|next_buffer_element(j,i) %}
			{% if upper2 > ni or (upper2 == ni and upper1 >= nj) %}
				get_{{c.name}}_{{nj}}_{{ni}}(&{% if nj == 0 %}signal_tmp{% else %}{% if c.type[nj-1].base == 'Integer' %}int_tmp{% elif c.type[nj-1].base == 'Byte' %}char_tmp{% else %}bool_tmp{% endif %}{% endif %}, *part, part_tmp);
			{% else %}
				get_{{c.name}}_{{nj}}_{{ni}}(&{% if nj == 0 %}signal_tmp{% else %}{% if c.type[nj-1].base == 'Integer' %}int_tmp{% elif c.type[nj-1].base == 'Byte' %}char_tmp{% else %}bool_tmp{% endif %}{% endif %}, part_tmp, *part);
			{% endif %}
			{% set PIDs = vectorelem_in_structure_map[c.name + "[" + j|string + "][" + i|string + "]"] %}
			{% if PIDs[1][0] == p %}
				set_left_{{c.name}}_{{j}}_{{i}}(part, {% if nj == 0 %}signal_tmp{% else %}{% if c.type[nj-1].base == 'Integer' %}int_tmp{% elif c.type[nj-1].base == 'Byte' %}char_tmp{% else %}bool_tmp{% endif %}{% endif %});
			{% else %}
				set_right_{{c.name}}_{{j}}_{{i}}(part, {% if nj == 0 %}signal_tmp{% else %}{% if c.type[nj-1].base == 'Integer' %}int_tmp{% elif c.type[nj-1].base == 'Byte' %}char_tmp{% else %}bool_tmp{% endif %}{% endif %});
			{% endif %}
			}
			else {
				set_left_{{c.name}}_{{j}}_{{i}}(part, 0);
				break;
			}
			{% endif %}
			{% endfor %}
			{% endfor %}
			break;
		{% endfor %}
		default:
			break;
	}
	{% else %}
	return;
	{% endif %}
}

{% endfor %}
{% for n in all_arrayindex_allocs_sizes %}
{% if loop.first %}
// Auxiliary functions to check for and obtain/store an array element with an index equal to the given expression e.
// There are functions for the various buffer sizes required to interpret the model.

// Store the given value v under index e. Check for presence of e in the index buffer. If not present, store e and v.
// Precondition: if e is not already present, there is space in the buffer to store it.
{% endif %}
template<class T>
inline __device__ void A_STR_{{n}}({% for i in range(0,n) %}array_indextype *idx_{{i}}, {% endfor %}{% for i in range(0,n) %}T *v_{{i}}, {% endfor %}array_indextype e, T v) {
{% for i in range(0,n) %}
{% if not loop.first%}	else {% else %}	{% endif %}if (((array_indextype) e) == *idx_{{i}}) {
		*v_{{i}} = v;
		return;
	}
	else if (*idx_{{i}} == EMPTY_INDEX) {
		*idx_{{i}} = (array_indextype) e;
		*v_{{i}} = v;
		return;
	}
{% endfor %}
}

{% endfor %}
{% for n in all_arrayindex_allocs_sizes %}
{% if loop.first %}
// Return the value stored at index e.
// Precondition: provided array contains the requested element.
{% endif %}
template<class T>
inline __device__ T A_LD_{{n}}({% for i in range(0,n) %}array_indextype idx_{{i}}, {% endfor %}{% for i in range(0,n) %}T v_{{i}}, {% endfor %}array_indextype e) {
{% for i in range(0,n) %}
{% if not loop.first%}	else {% else %}	{% endif %}if (((array_indextype) e) == idx_{{i}}) {
		return v_{{i}};
	}
{% endfor %}
	return T();
}

{% endfor %}

{% for n in all_arrayindex_allocs_sizes %}
{% if loop.first %}
// Check whether the given array index e is stored in the given array index buffer.
{% endif %}
inline __device__ bool A_IEX_{{n}}({% for i in range(0,n) %}array_indextype idx_{{i}}, {% endfor %}array_indextype e) {
{% for i in range(0,n) %}
{% if not loop.first%}	else {% else %}	{% endif %}if (((array_indextype) e) == idx_{{i}}) {
		return true;
	}
{% endfor %}
	return false;
}

{% endfor %}
{% for c in model.classes %}
{% set cloop = loop %}
{% for sm in c.statemachines %}
{% set smloop = loop %}
{% for a in alphabet[sm] if a in syncactions %}
{% if cloop.first and smloop.first and loop.first %}
// Action execution functions. For each state machine and action requiring synchronisation, there is a function returning for a given
// source state a target state that can be reached by performing the action. In case of non-determinism, repeated calls of the function
// will produce each of the different reachable states.
{% endif %}
inline __device__ statetype get_target_{{sm.name}}_{{a}}(statetype src, statetype prev_tgt) {
	switch (src) {
		{% set atrans = actiontargets[sm][a] %}
		{% for src, tgts in atrans|dictsort %}
		case {{src}}:
			switch (prev_tgt) {
				{% for j in range(0, tgts|length+1) %}
				{% if j == 0 %}
				case -1:
				{% else %}
				case {{tgts[j-1]}}:
				{% endif %}
					{% if j == tgts|length %}
					return -1;
					{% else %}
					return {{tgts[j]}};
					{% endif %}
				{% endfor %}
				default:
					return -1;
			}
		{% endfor %}
		default:
			return -1;
	}
}

{% endfor %}
{% endfor %}
{% endfor %}

// *** END FUNCTIONS FOR MODEL DATA RETRIEVAL AND STORAGE ***

// *** START FUNCTIONS FOR INTRA-WARP BITONIC MERGESORT (Fast Segmented Sort on GPUs, Hou et al., 2017) ***

inline __device__ void CMP_SWP(statetype *s0, statetype *s1, shared_indextype *p0, shared_indextype *p1) {
	statetype s_tmp;
	shared_indextype p_tmp;

	if (*s0 > *s1) {
		s_tmp = *s0;
		*s0 = *s1;
		*s1 = s_tmp;
		p_tmp = *p0;
		*p0 = *p1;
		*p1 = p_tmp;
	}
}

inline __device__ void EQL_SWP(statetype *s0, statetype *s1, shared_indextype *p0, shared_indextype *p1) {
	statetype s_tmp;
	shared_indextype p_tmp;

	if (*s0 != *s1) {
		s_tmp = *s0;
		*s0 = *s1;
		*s1 = s_tmp;
		p_tmp = *p0;
		*p0 = *p1;
		*p1 = p_tmp;
	}
}

inline __device__ void SWP(statetype *s0, statetype *s1, shared_indextype *p0, shared_indextype *p1) {
	statetype s_tmp;
	shared_indextype p_tmp;

	s_tmp = *s0;
	*s0 = *s1;
	*s1 = s_tmp;
	p_tmp = *p0;
	*p0 = *p1;
	*p1 = p_tmp;
}

inline __device__ void _exch_intxn({% for i in range(0,regsort_nr_el_per_thread) %}statetype *s{{i}}, {% endfor %}{% for i in range(0,regsort_nr_el_per_thread) %}shared_indextype *p{{i}}, {% endfor %}uint8_t mask, bool bit) {
	statetype ex_s0, ex_s1;
	shared_indextype ex_p0, ex_p1;
	{% if regsort_nr_el_per_thread > 2 %}
	{% for i in range (0,(regsort_nr_el_per_thread/2)|int) %}
	if (bit) SWP(s{{i}}, s{{(regsort_nr_el_per_thread-1-((i/2)|int*2)-(1-(i%2)))|int}}, p{{i}}, p{{(regsort_nr_el_per_thread-1-((i/2)|int*2)-(1-(i%2)))|int}});
	{% endfor %}
	{% endif %}
	{% for i in range(0,(regsort_nr_el_per_thread/2)|int) %}
	ex_s0 = *s{{i*2}};
	ex_s1 = __shfl_xor_sync(0xFFFFFFFF, {% if regsort_nr_el_per_thread > 1 %}*s{{i*2+1}}{% else %}*s{{i*2}}{% endif %}, mask);
	ex_p0 = *p{{i*2}};
	ex_p1 = __shfl_xor_sync(0xFFFFFFFF, {% if regsort_nr_el_per_thread > 1 %}*p{{i*2+1}}{% else %}*p{{i*2}}{% endif %}, mask);
	CMP_SWP(&ex_s0, &ex_s1, &ex_p0, &ex_p1);
	if (bit) EQL_SWP(&ex_s0, &ex_s1, &ex_p0, &ex_p1);
	*s{{i*2}} = ex_s0;
	{% if regsort_nr_el_per_thread > 1 %}
	*s{{i*2+1}} = __shfl_xor_sync(0xFFFFFFFF, ex_s1, mask);
	{% endif %}
	*p{{i*2}} = ex_p0;
	{% if regsort_nr_el_per_thread > 1 %}
	*p{{i*2+1}} = __shfl_xor_sync(0xFFFFFFFF, ex_p1, mask);
	{% endif %}
	{% endfor %}
	{% if regsort_nr_el_per_thread > 2 %}
	{% for i in range (0,(regsort_nr_el_per_thread/2)|int) %}
	if (bit) SWP(s{{i}}, s{{(regsort_nr_el_per_thread-1-((i/2)|int*2)-(1-(i%2)))|int}}, p{{i}}, p{{(regsort_nr_el_per_thread-1-((i/2)|int*2)-(1-(i%2)))|int}});
	{% endfor %}
	{% endif %}
}

inline __device__ void _exch_paral({% for i in range(0,regsort_nr_el_per_thread) %}statetype *s{{i}}, {% endfor %}{% for i in range(0,regsort_nr_el_per_thread) %}shared_indextype *p{{i}}, {% endfor %}uint8_t mask, bool bit) {
	statetype ex_s0, ex_s1;
	shared_indextype ex_p0, ex_p1;
	{% if regsort_nr_el_per_thread > 1 %}
	{% for i in range (0,(regsort_nr_el_per_thread/2)|int) %}
	if (bit) SWP(s{{i*2}}, s{{i*2+1}}, p{{i*2}}, p{{i*2+1}});
	{% endfor %}
	{% endif %}
	{% for i in range(0,(regsort_nr_el_per_thread/2)|int) %}
	ex_s0 = *s{{i*2}};
	ex_s1 = __shfl_xor_sync(0xFFFFFFFF, {% if regsort_nr_el_per_thread > 1 %}*s{{i*2+1}}{% else %}*s{{i*2}}{% endif %}, mask);
	ex_p0 = *p{{i*2}};
	ex_p1 = __shfl_xor_sync(0xFFFFFFFF, {% if regsort_nr_el_per_thread > 1 %}*p{{i*2+1}}{% else %}*p{{i*2}}{% endif %}, mask);
	CMP_SWP(&ex_s0, &ex_s1, &ex_p0, &ex_p1);
	if (bit) EQL_SWP(&ex_s0, &ex_s1, &ex_p0, &ex_p1);
	*s{{i*2}} = ex_s0;
	{% if regsort_nr_el_per_thread > 1 %}
	*s{{i*2+1}} = __shfl_xor_sync(0xFFFFFFFF, ex_s1, mask);
	{% endif %}
	*p{{i*2}} = ex_p0;
	{% if regsort_nr_el_per_thread > 1 %}
	*p{{i*2+1}} = __shfl_xor_sync(0xFFFFFFFF, ex_p1, mask);
	{% endif %}
	{% endfor %}
	{% if regsort_nr_el_per_thread > 1 %}
	{% for i in range (0,(regsort_nr_el_per_thread/2)|int) %}
	if (bit) SWP(s{{i*2}}, s{{i*2+1}}, p{{i*2}}, p{{i*2+1}});
	{% endfor %}
	{% endif %}
}

// The main bitonic sorting function, including loading the data to be sorted,
// and returning the tile index of the element to be subsequently used by the calling thread.
// wid is the ID of the warp executing the function. It is a parameter (as opposed to deriving the ID from the thread dynamically),
// to allow a thread to run the function with multiple IDs.
__device__ shared_indextype get_sorted_opentile_element(uint8_t wid) {
	statetype {% for i in range(0,regsort_nr_el_per_thread) %}s{{i}}{% if not loop.last %}, {% else %};{% endif %}{% endfor %}
	
	shared_indextype {% for i in range(0,regsort_nr_el_per_thread) %}p{{i}}, {% endfor %}p_tmp1, p_tmp2, p_result;
	
	// Load the tile indices.
	{% for i in range(0,regsort_nr_el_per_thread) %}
	{% if loop.last %}
	if ({{i*warpsize}}+LANE < OPENTILELEN) {
		{% if vectorsize > 30 %}
		asm("{\n\t"
			" cvt.u16.u32 %0, %1;\n\t"
			"}" : "=r"(p{{i}}) : "r"(shared[OPENTILEOFFSET+{{i*warpsize}}+LANE]));
		if (p{{i}} != EMPTYVECT16) {
		{% else %}
		p{{i}} = {{i+warpsize}}+LANE;
		if (shared[OPENTILEOFFSET+p{{i}}] != EMPTYVECT32) {
		{% endif %}
			// Retrieve corresponding state value.
			get_current_state(&s{{i}}, p{{i}}, wid / OPENTILE_WARP_WIDTH);
		}
		else {
			s{{i}} = NO_STATE;
		}
		p{{i}} = {{i*warpsize}}+LANE;
	}
	else {
		p{{i}} = EMPTYVECT16;
		s{{i}} = NO_STATE;
	}
	{% else %}
	{% if vectorsize > 30 %}
	asm("{\n\t"
		" cvt.u16.u32 %0, %1;\n\t"
		"}" : "=r"(p{{i}}) : "r"(shared[OPENTILEOFFSET+{{i*warpsize}}+LANE]));
	if (p{{i}} != EMPTYVECT16) {
	{% else %}
	p{{i}} = {{i*warpsize}}+LANE;
	if (shared[OPENTILEOFFSET+p{{i}}] != EMPTYVECT32) {
	{% endif %}
		// Retrieve corresponding state value.
		get_current_state(&s{{i}}, p{{i}}, wid / OPENTILE_WARP_WIDTH);
	}
	else {
		s{{i}} = NO_STATE;
	}
	{% if vectorsize > 30 %}
	p{{i}} = {{i*warpsize}}+LANE;
	{% endif %}
	{% endif %}
	{% endfor %}
	// Perform the sorting.
	{% for l in range(1, (regsort_nr_el_per_thread*warpsize)|log2+1)|reverse %}
	{% set coop_elem_num = (l-1)|pow2 %}
	{% set coop_thrd_num = ([warpsize|log2, l-1]|min)|pow2 %}
	{% set coop_elem_size = ((regsort_nr_el_per_thread*warpsize)|log2-l+1)|pow2 %}
	{% set coop_thrd_size = (warpsize|log2 - [warpsize|log2, l-1]|min)|pow2 %}
	{% if coop_thrd_size == 1 %}
	// exch_local intxn.
	{% set rmask = coop_elem_size - 1 %}
	{% set ns = namespace(L=[]) %}
	{% for i in range(0,regsort_nr_el_per_thread) %}
	{% if not i|in_list(ns.L) %}
	CMP_SWP(&s{{i}}, &s{{i|xor(rmask)}}, &p{{i}}, &p{{i|xor(rmask)}});
	{% set ns.L = ns.L + [i, i|xor(rmask)] %}
	{% endif %}
	{% endfor %}
	{% else %}
	_exch_intxn({% for i in range(0,regsort_nr_el_per_thread) %}&s{{i}}, {% endfor %}{% for i in range(0,regsort_nr_el_per_thread) %}&p{{i}}, {% endfor %}{{(coop_thrd_size-1)|hexa}}, (LANE & {{(((coop_thrd_size-1)|log2)|pow2)|hexa}}) != 0);
	{% endif %}
	{% for k in range(l+1, (regsort_nr_el_per_thread*warpsize)|log2+1) %}
	{% set coop_elem_num = (k-1)|pow2 %}
	{% set coop_thrd_num = ([warpsize|log2, k-1]|min)|pow2 %}
	{% set coop_elem_size = ((regsort_nr_el_per_thread*warpsize)|log2-k+1)|pow2 %}
	{% set coop_thrd_size = (warpsize|log2 - [warpsize|log2, k-1]|min)|pow2 %}
	{% if coop_thrd_size == 1 %}
	// exch_local paral.
	{% set rmask = coop_elem_size - 1 %}
	{% set rmask = rmask - rmask|bitshift_one_right %}
	{% set ns = namespace(L=[]) %}
	{% for i in range(0,regsort_nr_el_per_thread) %}
	{% if not i|in_list(ns.L) %}
	CMP_SWP(&s{{i}}, &s{{i|xor(rmask)}}, &p{{i}}, &p{{i|xor(rmask)}});
	{% set ns.L = ns.L + [i, i|xor(rmask)] %}
	{% endif %}
	{% endfor %}
	{% else %}
	{% set tmask = coop_thrd_size - 1 %}
	{% set tmask = tmask - tmask|bitshift_one_right %}
	_exch_paral({% for i in range(0,regsort_nr_el_per_thread) %}&s{{i}}, {% endfor %}{% for i in range(0,regsort_nr_el_per_thread) %}&p{{i}}, {% endfor %}{{tmask|hexa}}, (LANE & {{(((coop_thrd_size - 1)|log2)|pow2)|hexa}}) != 0);
	{% endif %}
	{% endfor %}
	{% endfor %}

	// Finally, retrieve the index of the tile element of interest for the current thread.
	uint8_t offset = wid % OPENTILE_WARP_WIDTH;
	{% for i in range(0,regsort_nr_el_per_thread) %}
	// If the index of the p{{i}} element of the thread is within the range of interest, prepare it for communication.
	if (LANE*{{regsort_nr_el_per_thread}}+{{i}} >= offset*WARP_SIZE && LANE*{{regsort_nr_el_per_thread}}+{{i}} < (offset+1)*WARP_SIZE) {
		p_tmp1 = p{{i}};
	}
	__syncwarp();
	// Retrieve from the thread that holds the element of interest for the current thread the prepared value (if it exists).
	p_tmp2 = __shfl_sync(0xFFFFFFFF, p_tmp1, ((offset*WARP_SIZE)+LANE) / {{regsort_nr_el_per_thread}});
	// If the value was indeed prepared by the source thread, store it.
	if (LANE & {{regsort_nr_el_per_thread-1}} == {{i}}) {
		// Value of interest is ready to be fetched.
		p_result = p_tmp2;
	}
	{% endfor %}
	return p_result;
}

//*** END FUNCTIONS FOR INTRA-WARP BITONIC MERGESORT ***

// Exploration functions to traverse outgoing transitions of the various states.
{% for i in range(0,smnames|length) %}
inline __device__ void explore_{{state_order[i]|replace("'","_")}}(shared_indextype node_index) {
	// Fetch the current state of the state machine.
	statetype current;
	get_current_state(&current, node_index, {{i}});
	statetype target = NO_STATE;
	nodetype part1, part2;
	{% if vectorsize > 62 %}
	shared_inttype part_cachepointers;
	{% else %}
	part1 = shared[OPENTILEOFFSET+node_index];
	{% endif %}
	switch (current) {
		{% for s in smname_to_object[state_order[i]][1].states %}
		{% set o = smname_to_object[state_order[i]][0] %}
		{% set sm = smname_to_object[state_order[i]][1] %}
		{% if s|nr_of_transitions_to_be_processed_by(i,o) > 0 %}
		case {{state_id[s]}}:
			{% set indent = "" %}
			{% set buffer_allocs = s|object_trans_to_be_processed_by_sm_thread(o)|get_buffer_allocs %}
			{% if buffer_allocs[0] + buffer_allocs[1] + buffer_allocs[2] + buffer_allocs[3] + buffer_allocs[4] > 0 %}
			// Allocate register memory to process transition(s).
			{% endif %}
			{% if buffer_allocs[0] > 0 %}
			elem_inttype {% for j in range(0,buffer_allocs[0]) %}buf32_{{j}}{{', ' if not loop.last}}{% endfor %};
			{% endif %}
			{% if buffer_allocs[1] > 0 %}
			shared_indextype {% for j in range(0,buffer_allocs[1]) %}buf16_{{j}}{{', ' if not loop.last}}{% endfor %};
			{% endif %}
			{% if buffer_allocs[2] > 0 %}
			elem_chartype {% for j in range(0,buffer_allocs[2]) %}buf8_{{j}}{{', ' if not loop.last}}{% endfor %};
			{% endif %}
			{% if buffer_allocs[3] > 0 %}
			bool {% for j in range(0,buffer_allocs[3]) %}buf1_{{j}}{{', ' if not loop.last}}{% endfor %};
			{% endif %}
			{% if buffer_allocs[4] > 0 %}
			// Allocate register memory for dynamic array indexing.
			array_indextype {% for j in range(0,buffer_allocs[4]) %}idx_{{j}}{{', ' if not loop.last}}{% endfor %};
			{% endif %}
			{% set ns = namespace(lastprio=100, prio_nestings=0) %}
			{% for t in s|outgoingtrans(sm.transitions) %}
			{% if t|must_be_processed_by(i,o) %}
			{% if t.priority > ns.lastprio %}
			if (target == NO_STATE) {
			{% set ns.prio_nestings = ns.prio_nestings + 1 %}
			{% set indent = indent + "\t" %}
			{% endif %}
			{% set ns.lastprio = t.priority %}
			{% set st = t.statements[0] %}
			{% set allocs = t|get_buffer_arrayindex_allocs(o) %}
			
			{{indent}}// {{s.name}} --{ {{st|getlabel}} }--> {{t.target.name}}
			
			{% set M = t|map_variables_on_buffer(o,buffer_allocs) %}
			{% if st.__class__.__name__ == 'ReceiveSignal' %}
			{% if st|cudarecsizeguard(M,o) != "" %}
			{{indent}}// Fetch buffer size value.
			{% set ch = connected_channel[(o, st.target)] %}
			{% set VP = [(ch,"_size")]|get_vectorparts(o) %}
			{% if vectorsize > 62 %}
			{{indent}}part1 = get_vectorpart(node_index, {{VP[0]}});
			{% if VP|length > 1 %}
			{{indent}}part2 = get_vectorpart(node_index, {{VP[1]}});
			{% endif %}
			{% endif %}
			{{indent}}get_{{ch.name}}_size(&{{M[(ch,"_size")][0]}}_{{M[(ch,"_size")][1]}}, part1, part2);
			{{indent}}if ({{st|cudarecsizeguard(M,o)}}) {
			{% set indent = indent + "\t" %}
			{% endif %}
			{% endif %}
			{% set fetchcode = st|cudafetchdata(indent|length+3, o, M, True, True) %}
			{% if fetchcode != "" %}
			{{indent}}{{fetchcode}}
			{% endif %}
			{{indent}}// Statement computation.
			{% if st|cudaguard(M,o) != "" %}
			{{indent}}if ({{st|cudaguard(M,o)}}) {
			{% set indent = indent + "\t" %}
			{% endif %}
			{% set fetchcode = st|cudafetchdata(indent|length+3, o, M, False, False) %}
			{% if fetchcode != "" %}
			{{indent}}{{fetchcode}}
			{% endif %}
			{% if st|cudastatement(1,o,M) != "" %}
			{{indent}}{{st|cudastatement(indent|length+3,o,M)}}{% endif %}
			{% if st|cudaguard(M,o) != "" %}
			{% set indent = indent[:-1] %}
			{{indent}}}
			{% endif %}
			{% if st.__class__.__name__ == "ReceiveSignal" %}
			{% if st|cudarecsizeguard(M,o) != "" %}
			}
			{% endif %}
			{% endif %}
			{% endif %}
			{% for j in range(0, ns.prio_nestings) %}
			{% set indent = indent[:-1] %}
			{{indent}}}
			{% endfor %}
			{% endfor %}
			break;
		{% endif %}
		{% endfor %}
		default:
			break;
	}
}

{% endfor %}
// Successor construction function for a particular state machine. Given a state vector, construct its successor state vectors w.r.t. the state machine, and store them in cache.
// Vgtid is the identity of the thread calling the function (id of thread relevant for successor generation).
inline __device__ void get_successors_of_sm(shared_indextype node_index, uint8_t vgtid) {
	// explore the outgoing transitions of the current state of the state machine assigned to vgtid.
	switch (vgtid) {
		{% for i in range(0,smnames|length) %}
		case {{i}}:
			explore_{{state_order[i]|replace("'","_")}}(node_index);
			break;
		{% endfor %}
		default:
			break;
	}
}

// Kernel function to start parallel successor generation.
{% if vectorsize > 30 %}
// Precondition: a tile of vectortree pointers to roots of cache-preloaded vectortrees is stored in the shared memory.
{% else %}
// Precondition: a tile of state nodes is stored in the shared memory.
{% endif %}
inline __device__ void GENERATE_SUCCESSORS() {
	// Iterate over the designated work.
	shared_indextype entry_id;
	{% if no_regsort %}
	shared_indextype entry_state_id;
	{% endif %}
	{% if vectorsize > 30 %}
	shared_inttype src_state;
	{% endif %}
	{% if gpuexplore2_succdist %}
	for (shared_indextype i = THREAD_ID; i < (OPENTILECOUNT * NR_SMS); i += BLOCK_SIZE) {
		entry_id = i / NR_SMS;
		entry_state_id = i - (entry_id * NR_SMS);
		{% if vectorsize > 30 %}
		src_state = shared[OPENTILEOFFSET+entry_id];
		{% endif %}
		get_successors_of_sm({% if vectorsize > 30 %}(shared_indextype) src_state{% else %}entry_id{% endif %}, entry_state_id);
	}
	{% else %}
	{% if no_regsort %}
	entry_id = ((WARP_ID % OPENTILE_WARP_WIDTH) * WARP_SIZE) + LANE;
	if (entry_id < OPENTILECOUNT) {
	{% endif %}
	for (shared_indextype i = WARP_ID; i/OPENTILE_WARP_WIDTH < NR_SMS; i += NR_WARPS_PER_BLOCK) {	
		{% if not no_regsort %}
		entry_id = get_sorted_opentile_element(i);
		if (entry_id < OPENTILECOUNT) {
		{% endif %}
			{% if vectorsize > 30 %}
			src_state = shared[OPENTILEOFFSET+entry_id];
			{% endif %}
			get_successors_of_sm({% if vectorsize > 30 %}(shared_indextype) src_state{% else %}entry_id{% endif %}, i/OPENTILE_WARP_WIDTH);
		{% if not no_regsort %}
		}
		{% endif %}
	}
	{% if no_regsort %}
	}
	{% endif %}
	{% endif %}
} 

// *** START PRINT FUNCTIONS ***

void print_content_hash_table(FILE* stream, compressed_nodetype *q{% if compact_hash_table %}, indextype non_root_offset{% else %}, indextype q_size{% endif %}) {
	for (indextype i = 0; i < {% if compact_hash_table %}non_root_offset{% else %}q_size{% endif %}; i++) {
		{% if not compact_hash_table and vectorsize > 63 %}
		if (is_root(q[i])) {
		{% else %}
		if (q[i] != {% if compact_hash_table %}EMPTY_COMPRESSED_NODE{% else %}EMPTY_NODE{% endif %}) {
		{% endif %}
			// Retrieve state vector.
			nodetype {% if vectorsize > 62 %}root{% else %}part0{% endif %} = HT_RETRIEVE(q, i{% if compact_hash_table %}, non_root_offset{% endif %});
			{% if vectorsize > 62 %}
			{% for i in range(0,vectorstructure|length) %}
			nodetype part{{i}} = direct_get_vectorpart_{{i}}(q, root);
			{% endfor %}
			{% endif %}
			// Print the contents of the state.
			nodetype *p1, *p2;
			statetype e_st;
			elem_booltype e_b;
			elem_chartype e_c;
			elem_inttype e_i;
			fprintf(stream, "-----\n");
			{% if vectorsize <= 62 %}
			p1 = &part0;
			p2 = &part0;
			{% endif %}
			{% for s in vectorelem_in_structure_map.keys() %}
			{% set size = vectorelem_in_structure_map[s][0] %}
			{% set PIDs = vectorelem_in_structure_map[s] %}
			{% if vectorsize > 62 %}
			p1 = &part{{PIDs[1][0]}};
			{% if PIDs|length > 2 %}
			p2 = &part{{PIDs[2][0]}};
			{% endif %}
			{% endif %}
			host_get_{{s|replace("[","_")|replace("]","")|replace("'","_")}}({% if s|is_state %}&e_st{% elif size == 1 %}&e_b{% elif size < 32 %}&e_c{% else %}&e_i{% endif %}, *p1, *p2);
			fprintf(stream, "{{s|vector_element_string_desc}} {{s}}: %u\n", (uint32_t) {% if s|is_state %}e_st{% elif size == 1 %}e_b{% elif size < 32 %}e_c{% else %}e_i{% endif %});
			{% endfor %}
			fprintf(stream, "-----\n");
		}
	}
}

// *** END PRINT FUNCTIONS ***